# Awesome llm agents

- [Awesome llm agents](#awesome-llm-agents)
	- [Survey](#survey)
	- [LLM OS](#llm-os)
	- [Agents](#agents)
		- [Other](#other)
	- [AutoGPT](#autogpt)
		- [Other](#other-1)
	- [Augmented LLM](#augmented-llm)
		- [Other](#other-2)
	- [Web browsing](#web-browsing)
		- [Other](#other-3)
	- [Retrieval agumented generation](#retrieval-agumented-generation)
		- [Other](#other-4)
	- [Code Interpreter](#code-interpreter)
	- [GPTs](#gpts)
		- [Plugins](#plugins)
		- [Other](#other-5)
	- [Evaluation](#evaluation)
	- [Other](#other-6)
	- [Extra reference](#extra-reference)

## Survey
- **[LLM Powered Autonomous Agents | Lil'Log]**(https://lilianweng.github.io/posts/2023-06-23-agent/)

	 ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652350213&idx=4&sn=47bef78ae85d99fccc45487e2fb1ff6b))
 
## LLM OS
- [At the Intersection of LLMs and Kernels - Research Roundup](https://charlesfrye.github.io/programming/2023/11/10/llms-systems.html)
- [**llama2.c**](https://github.com/trholding/llama2.c) - trholding ![Star](https://img.shields.io/github/stars/trholding/llama2.c.svg?style=social&label=Star)

	 *Llama 2 Everywhere (L2E)* ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-10-07-14))
	
- [**MemGPT**](https://github.com/cpacker/MemGPT) - cpacker ![Star](https://img.shields.io/github/stars/cpacker/MemGPT.svg?style=social&label=Star)

	 *Teaching LLMs memory management for unbounded context üìöü¶ô*

	 ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-10-18-4))
## Agents
- [**multi-agent-postgres-data-analytics**](https://github.com/disler/multi-agent-postgres-data-analytics) - disler ![Star](https://img.shields.io/github/stars/disler/multi-agent-postgres-data-analytics.svg?style=social&label=Star)

	 *The way we interact with our data is changing.*
- [**ProAgent**](https://github.com/OpenBMB/ProAgent) - OpenBMB ![Star](https://img.shields.io/github/stars/OpenBMB/ProAgent.svg?style=social&label=Star)

	 ¬∑ ([ProAgent](https://github.com/OpenBMB/ProAgent/blob/main/paper/paper.pdf) - OpenBMB) ![Star](https://img.shields.io/github/stars/OpenBMB/ProAgent.svg?style=social&label=Star)
- **JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal
  Language Models**, `arXiv, 2311.05997`, [arxiv](http://arxiv.org/abs/2311.05997v1), [pdf](http://arxiv.org/pdf/2311.05997v1.pdf), cication: [**-1**](None)

	 *Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang* ¬∑ ([craftjarvis-jarvis1.github](https://craftjarvis-jarvis1.github.io))
- **Lumos: Learning Agents with Unified Data, Modular Design, and
  Open-Source LLMs**, `arXiv, 2311.05657`, [arxiv](http://arxiv.org/abs/2311.05657v1), [pdf](http://arxiv.org/pdf/2311.05657v1.pdf), cication: [**-1**](None)

	 *Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin* ¬∑ ([lumos](https://github.com/allenai/lumos) - allenai) ![Star](https://img.shields.io/github/stars/allenai/lumos.svg?style=social&label=Star) ¬∑ ([allenai.github](https://allenai.github.io/lumos/))
- [**OpenAI_Agent_Swarm**](https://github.com/daveshap/OpenAI_Agent_Swarm) - daveshap ![Star](https://img.shields.io/github/stars/daveshap/OpenAI_Agent_Swarm.svg?style=social&label=Star)

	 *HAAS = Hierarchical Autonomous Agent Swarm - "Resistance is futile!"*
- **LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents**, `arXiv, 2311.05437`, [arxiv](http://arxiv.org/abs/2311.05437v1), [pdf](http://arxiv.org/pdf/2311.05437v1.pdf), cication: [**-1**](None)

	 *Shilong Liu, Hao Cheng, Haotian Liu, Hao Zhang, Feng Li, Tianhe Ren, Xueyan Zou, Jianwei Yang, Hang Su, Jun Zhu*

- **Octopus: Embodied Vision-Language Programmer from Environmental Feedback**, `arXiv, 2310.08588`, [arxiv](http://arxiv.org/abs/2310.08588v1), [pdf](http://arxiv.org/pdf/2310.08588v1.pdf), cication: [**-1**](None)

	 *Jingkang Yang, Yuhao Dong, Shuai Liu, Bo Li, Ziyue Wang, Chencheng Jiang, Haoran Tan, Jiamu Kang, Yuanhan Zhang, Kaiyang Zhou* ¬∑ ([Octopus](https://github.com/dongyh20/Octopus) - dongyh20) ![Star](https://img.shields.io/github/stars/dongyh20/Octopus.svg?style=social&label=Star) ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652403403&idx=5&sn=8c265c36ba692eb614e537894406b72b))
- **Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent
  Learning**, `arXiv, 2311.03736`, [arxiv](http://arxiv.org/abs/2311.03736v1), [pdf](http://arxiv.org/pdf/2311.03736v1.pdf), cication: [**-1**](None)

	 *Joseph Su√°rez, Phillip Isola, Kyoung Whan Choe, David Bloomin, Hao Xiang Li, Nikhil Pinnaparaju, Nishaanth Kanna, Daniel Scott, Ryan Sullivan, Rose S. Shuman*
- [From Copilot to CoOrchestration](https://blog.salesforceairesearch.com/from-copilot-to-coorchestration/)
- **OpenAgents: An Open Platform for Language Agents in the Wild**, `arXiv, 2310.10634`, [arxiv](http://arxiv.org/abs/2310.10634v1), [pdf](http://arxiv.org/pdf/2310.10634v1.pdf), cication: [**-1**](None)

	 *Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu*
- [**agenttuning**](https://github.com/thudm/agenttuning) - thudm ![Star](https://img.shields.io/github/stars/thudm/agenttuning.svg?style=social&label=Star)

	 *AgentTuning: Enabling Generalized Agent Abilities for LLMs*
- **Humanoid Agents: Platform for Simulating Human-like Generative Agents**, `arXiv, 2310.05418`, [arxiv](http://arxiv.org/abs/2310.05418v1), [pdf](http://arxiv.org/pdf/2310.05418v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=16164127293972935454&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhilin Wang, Yu Ying Chiu, Yu Cheung Chiu* ¬∑ ([humanoidagents](https://github.com/humanoidagents/humanoidagents) - humanoidagents) ![Star](https://img.shields.io/github/stars/humanoidagents/humanoidagents.svg?style=social&label=Star)
- [**XAgent**](https://github.com/OpenBMB/XAgent) - OpenBMB ![Star](https://img.shields.io/github/stars/OpenBMB/XAgent.svg?style=social&label=Star)

	 *An Autonomous LLM Agent for Complex Task Solving* ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-10-17-7))
- **Reason for Future, Act for Now: A Principled Framework for Autonomous
  LLM Agents with Provable Sample Efficiency**, `arXiv, 2309.17382`, [arxiv](http://arxiv.org/abs/2309.17382v2), [pdf](http://arxiv.org/pdf/2309.17382v2.pdf), cication: [**-1**](None)

	 *Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke, Boyi Liu, Zhaoran Wang*
- **Humanoid Agents: Platform for Simulating Human-like Generative Agents**, `arXiv, 2310.05418`, [arxiv](http://arxiv.org/abs/2310.05418v1), [pdf](http://arxiv.org/pdf/2310.05418v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=16164127293972935454&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhilin Wang, Yu Ying Chiu, Yu Cheung Chiu* ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652391398&idx=1&sn=0c2ed56e8721858398a8e3b501349a5c))
- **A Zero-Shot Language Agent for Computer Control with Structured
  Reflection**, `arXiv, 2310.08740`, [arxiv](http://arxiv.org/abs/2310.08740v3), [pdf](http://arxiv.org/pdf/2310.08740v3.pdf), cication: [**-1**](None)

	 *Tao Li, Gang Li, Zhiwei Deng, Bryan Wang, Yang Li*
- **Lemur: Harmonizing Natural Language and Code for Language Agents**, `arXiv, 2310.06830`, [arxiv](http://arxiv.org/abs/2310.06830v1), [pdf](http://arxiv.org/pdf/2310.06830v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=14859965768820951174&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie*
- **EcoAssistant: Using LLM Assistant More Affordably and Accurately**, `arXiv, 2310.03046`, [arxiv](http://arxiv.org/abs/2310.03046v1), [pdf](http://arxiv.org/pdf/2310.03046v1.pdf), cication: [**-1**](None)

	 *Jieyu Zhang, Ranjay Krishna, Ahmed H. Awadallah, Chi Wang*
- [**khoj**](https://github.com/khoj-ai/khoj) - khoj-ai ![Star](https://img.shields.io/github/stars/khoj-ai/khoj.svg?style=social&label=Star)

	 *An AI personal assistant for your digital brain*
- **AssistGPT: A General Multi-modal Assistant that can Plan, Execute,
  Inspect, and Learn**, `arXiv, 2306.08640`, [arxiv](http://arxiv.org/abs/2306.08640v2), [pdf](http://arxiv.org/pdf/2306.08640v2.pdf), cication: [**-1**](None)

	 *Difei Gao, Lei Ji, Luowei Zhou, Kevin Qinghong Lin, Joya Chen, Zihan Fan, Mike Zheng Shou*

- **Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind
  Aware GPT-4**, `arXiv, 2309.17277`, [arxiv](http://arxiv.org/abs/2309.17277v2), [pdf](http://arxiv.org/pdf/2309.17277v2.pdf), cication: [**-1**](None)

	 *Jiaxian Guo, Bo Yang, Paul Yoo, Bill Yuchen Lin, Yusuke Iwasawa, Yutaka Matsuo*
- [**autogen**](https://github.com/microsoft/autogen) - microsoft ![Star](https://img.shields.io/github/stars/microsoft/autogen.svg?style=social&label=Star)

	 *Enable Next-Gen Large Language Model Applications. Join our Discord: https://discord.gg/pAbnFJrkgZ*
- **How FaR Are Large Language Models From Agents with Theory-of-Mind?**, `arXiv, 2310.03051`, [arxiv](http://arxiv.org/abs/2310.03051v1), [pdf](http://arxiv.org/pdf/2310.03051v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=7978252366042560178&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya Gupta, Kevin R. McKee, Ari Holtzman, Jay Pujara, Xiang Ren, Swaroop Mishra, Aida Nematzadeh* ¬∑ ([qbitai](https://www.qbitai.com/2023/10/89929.html))
- [**AutoAgents**](https://github.com/LinkSoul-AI/AutoAgents) - LinkSoul-AI ![Star](https://img.shields.io/github/stars/LinkSoul-AI/AutoAgents.svg?style=social&label=Star)

	 *Generate different roles for GPTs to form a collaborative entity for complex tasks.*
- **LASER: LLM Agent with State-Space Exploration for Web Navigation**, `arXiv, 2309.08172`, [arxiv](http://arxiv.org/abs/2309.08172v1), [pdf](http://arxiv.org/pdf/2309.08172v1.pdf), cication: [**-1**](None)

	 *Kaixin Ma, Hongming Zhang, Hongwei Wang, Xiaoman Pan, Dong Yu*
- **Agents: An Open-source Framework for Autonomous Language Agents**, `arXiv, 2309.07870`, [arxiv](http://arxiv.org/abs/2309.07870v2), [pdf](http://arxiv.org/pdf/2309.07870v2.pdf), cication: [**4**](https://scholar.google.com/scholar?cites=17378587224686315113&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang* ¬∑ ([agents](https://github.com/aiwaves-cn/agents) - aiwaves-cn) ![Star](https://img.shields.io/github/stars/aiwaves-cn/agents.svg?style=social&label=Star)
- [MindAgent: Emergent Gaming Interaction - Microsoft Research](https://www.microsoft.com/en-us/research/publication/mindagent-emergent-gaming-interaction/)

	 ¬∑ ([qbitai](https://www.qbitai.com/2023/09/85935.html))
- **The Rise and Potential of Large Language Model Based Agents: A Survey**, `arXiv, 2309.07864`, [arxiv](http://arxiv.org/abs/2309.07864v3), [pdf](http://arxiv.org/pdf/2309.07864v3.pdf), cication: [**23**](https://scholar.google.com/scholar?cites=10681175205933279445&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou* ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-09-19-8)) ¬∑ ([LLM-Agent-Paper-List](https://github.com/WooooDyy/LLM-Agent-Paper-List) - WooooDyy) ![Star](https://img.shields.io/github/stars/WooooDyy/LLM-Agent-Paper-List.svg?style=social&label=Star)
- **Cognitive Architectures for Language Agents**, `arXiv, 2309.02427`, [arxiv](http://arxiv.org/abs/2309.02427v2), [pdf](http://arxiv.org/pdf/2309.02427v2.pdf), cication: [**11**](https://scholar.google.com/scholar?cites=4166085628183562359&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L. Griffiths* ¬∑ ([awesome-language-agents](https://github.com/ysymyth/awesome-language-agents) - ysymyth) ![Star](https://img.shields.io/github/stars/ysymyth/awesome-language-agents.svg?style=social&label=Star)
- **AgentVerse: Facilitating Multi-Agent Collaboration and Exploring
  Emergent Behaviors**, `arXiv, 2308.10848`, [arxiv](http://arxiv.org/abs/2308.10848v3), [pdf](http://arxiv.org/pdf/2308.10848v3.pdf), cication: [**13**](https://scholar.google.com/scholar?cites=13815451266857953260&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian* ¬∑ ([agentverse](https://github.com/openbmb/agentverse) - openbmb) ![Star](https://img.shields.io/github/stars/openbmb/agentverse.svg?style=social&label=Star)
- [**AI-town**](https://github.com/a16z-infra/AI-town) - a16z-infra ![Star](https://img.shields.io/github/stars/a16z-infra/AI-town.svg?style=social&label=Star)

	 *A MIT-licensed, deployable starter kit for building and customizing your own version of AI town - a virtual town where AI characters live, chat and socialize.*
- **TPTU: Large Language Model-based AI Agents for Task Planning and Tool
  Usage**, `arXiv, 2308.03427`, [arxiv](http://arxiv.org/abs/2308.03427v3), [pdf](http://arxiv.org/pdf/2308.03427v3.pdf), cication: [**11**](https://scholar.google.com/scholar?cites=215173853357937829&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Ziyue Li, Xingyu Zeng*
- [SHOW-1 and Showrunner Agents in Multi-Agent Simulations](https://fablestudio.github.io/showrunner-agents/)

	 ¬∑ ([fablestudio.github](https://fablestudio.github.io/showrunner-agents/)) ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652355390&idx=2&sn=ebceb562ebbf687157a5e44ff90ad91f))
- **Building Cooperative Embodied Agents Modularly with Large Language
  Models**, `arXiv, 2307.02485`, [arxiv](http://arxiv.org/abs/2307.02485v1), [pdf](http://arxiv.org/pdf/2307.02485v1.pdf), cication: [**-1**](None)

	 *Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B. Tenenbaum, Tianmin Shu, Chuang Gan*

- [**autotab-starter**](https://github.com/Planetary-Computers/autotab-starter) - Planetary-Computers ![Star](https://img.shields.io/github/stars/Planetary-Computers/autotab-starter.svg?style=social&label=Star)

	 *Build browser agents for real world tasks*
- [**openagents**](https://github.com/xlang-ai/openagents) - xlang-ai ![Star](https://img.shields.io/github/stars/xlang-ai/openagents.svg?style=social&label=Star)

	 *OpenAgents: An Open Platform for Language Agents in the Wild*
- [**octopus**](https://github.com/dongyh20/octopus) - dongyh20 ![Star](https://img.shields.io/github/stars/dongyh20/octopus.svg?style=social&label=Star)

	 *üêôOctopus, an embodied vision-language model trained with RLEF, emerging superior in embodied visual planning and programming.*
- [**gollie**](https://github.com/hitz-zentroa/gollie) - hitz-zentroa ![Star](https://img.shields.io/github/stars/hitz-zentroa/gollie.svg?style=social&label=Star)

	 *Guideline following Large Language Model for Information Extraction*
- [NexusRaven-13B: Surpassing the state-of-the-art in open-source function calling LLMs.](https://huggingface.co/Nexusflow/NexusRaven-13B)

	 ¬∑ ([nexusflow](https://nexusflow.ai/blog))
- **ModelScope-Agent: Building Your Customizable Agent System with
  Open-source Large Language Models**, `arXiv, 2309.00986`, [arxiv](http://arxiv.org/abs/2309.00986v1), [pdf](http://arxiv.org/pdf/2309.00986v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=2246653548879289665&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Chenliang Li, Hehong Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng* ¬∑ ([modelscope-agent](https://github.com/modelscope/modelscope-agent) - modelscope) ![Star](https://img.shields.io/github/stars/modelscope/modelscope-agent.svg?style=social&label=Star)
- [**trl-text-environment**](https://huggingface.co/spaces/trl-lib/trl-text-environment) - trl-lib ü§ó
- [**awesome-ai-devtools**](https://github.com/jamesmurdza/awesome-ai-devtools#agents) - jamesmurdza ![Star](https://img.shields.io/github/stars/jamesmurdza/awesome-ai-devtools.svg?style=social&label=Star)

	 *Curated list of AI-powered developer tools.*
- **TPTU: Large Language Model-based AI Agents for Task Planning and Tool
  Usage**, `arXiv, 2308.03427`, [arxiv](http://arxiv.org/abs/2308.03427v3), [pdf](http://arxiv.org/pdf/2308.03427v3.pdf), cication: [**11**](https://scholar.google.com/scholar?cites=215173853357937829&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Ziyue Li, Xingyu Zeng*
- [**functionary**](https://github.com/musabgultekin/functionary) - musabgultekin ![Star](https://img.shields.io/github/stars/musabgultekin/functionary.svg?style=social&label=Star)

	 *Chat language model that can interpret and execute functions/plugins*
- **Tool Documentation Enables Zero-Shot Tool-Usage with Large Language
  Models**, `arXiv, 2308.00675`, [arxiv](http://arxiv.org/abs/2308.00675v1), [pdf](http://arxiv.org/pdf/2308.00675v1.pdf), cication: [**4**](https://scholar.google.com/scholar?cites=10301950723538634763&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister*
- [**gorilla**](https://github.com/ShishirPatil/gorilla) - ShishirPatil ![Star](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?style=social&label=Star)

	 *Gorilla: An API store for LLMs*
- **ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world
  APIs**, `arXiv, 2307.16789`, [arxiv](http://arxiv.org/abs/2307.16789v2), [pdf](http://arxiv.org/pdf/2307.16789v2.pdf), cication: [**33**](https://scholar.google.com/scholar?cites=18087391995547841318&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian* ¬∑ ([ToolBench](https://github.com/OpenBMB/ToolBench) - OpenBMB) ![Star](https://img.shields.io/github/stars/OpenBMB/ToolBench.svg?style=social&label=Star)
- **Android in the Wild: A Large-Scale Dataset for Android Device Control**, `arXiv, 2307.10088`, [arxiv](http://arxiv.org/abs/2307.10088v2), [pdf](http://arxiv.org/pdf/2307.10088v2.pdf), cication: [**4**](https://scholar.google.com/scholar?cites=12177699480233945897&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, Timothy Lillicrap* ¬∑ ([google-research](https://github.com/google-research/google-research/tree/master/android_in_the_wild) - google-research) ![Star](https://img.shields.io/github/stars/google-research/google-research.svg?style=social&label=Star)
- [**amadeusgpt**](https://github.com/adaptivemotorcontrollab/amadeusgpt) - adaptivemotorcontrollab ![Star](https://img.shields.io/github/stars/adaptivemotorcontrollab/amadeusgpt.svg?style=social&label=Star)

	 *We turn natural language descriptions of behaviors into machine-executable code*
- **Towards Language Models That Can See: Computer Vision Through the LENS
  of Natural Language**, `arXiv, 2306.16410`, [arxiv](http://arxiv.org/abs/2306.16410v1), [pdf](http://arxiv.org/pdf/2306.16410v1.pdf), cication: [**-1**](None)

	 *William Berrios, Gautam Mittal, Tristan Thrush, Douwe Kiela, Amanpreet Singh* ¬∑ ([lens](https://github.com/contextualai/lens) - contextualai) ![Star](https://img.shields.io/github/stars/contextualai/lens.svg?style=social&label=Star)
- **ViperGPT: Visual Inference via Python Execution for Reasoning**, `arXiv, 2303.08128`, [arxiv](http://arxiv.org/abs/2303.08128v1), [pdf](http://arxiv.org/pdf/2303.08128v1.pdf), cication: [**76**](https://scholar.google.com/scholar?cites=4650814090908712272&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *D√≠dac Sur√≠s, Sachit Menon, Carl Vondrick*
- **HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging
  Face**, `arXiv, 2303.17580`, [arxiv](http://arxiv.org/abs/2303.17580v3), [pdf](http://arxiv.org/pdf/2303.17580v3.pdf), cication: [**233**](https://scholar.google.com/scholar?cites=14990757005844289549&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang*
- **LOVM: Language-Only Vision Model Selection**, `arXiv, 2306.08893`, [arxiv](http://arxiv.org/abs/2306.08893v1), [pdf](http://arxiv.org/pdf/2306.08893v1.pdf), cication: [**-1**](None)

	 *Orr Zohar, Shih-Cheng Huang, Kuan-Chieh Wang, Serena Yeung*
- **CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning
  of Large Language Models**, `arXiv, 2305.14318`, [arxiv](http://arxiv.org/abs/2305.14318v2), [pdf](http://arxiv.org/pdf/2305.14318v2.pdf), cication: [**7**](https://scholar.google.com/scholar?cites=11838226438475363604&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Cheng Qian, Chi Han, Yi R. Fung, Yujia Qin, Zhiyuan Liu, Heng Ji* ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-06-12-4))
- [**gorilla**](https://github.com/ShishirPatil/gorilla/) - ShishirPatil ![Star](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?style=social&label=Star)

	 *Gorilla: An API store for LLMs* ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-05-26-9)) ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652338143&idx=5&sn=24b350988a7328ac72bfa04a857e000e))
- **ReWOO: Decoupling Reasoning from Observations for Efficient Augmented
  Language Models**, `arXiv, 2305.18323`, [arxiv](http://arxiv.org/abs/2305.18323v1), [pdf](http://arxiv.org/pdf/2305.18323v1.pdf), cication: [**10**](https://scholar.google.com/scholar?cites=16471505160659542910&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu* ¬∑ ([rewoo](https://github.com/billxbf/rewoo) - billxbf) ![Star](https://img.shields.io/github/stars/billxbf/rewoo.svg?style=social&label=Star)
- **OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities**, `arXiv, 2305.16334`, [arxiv](http://arxiv.org/abs/2305.16334v1), [pdf](http://arxiv.org/pdf/2305.16334v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=2252208966238122327&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yuanzhen Xie, Tao Xie, Mingxiong Lin, WenTao Wei, Chenglin Li, Beibei Kong, Lei Chen, Chengxiang Zhuo, Bo Hu, Zang Li* ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652336823&idx=4&sn=c0559ee72df731edbb381b7593f623be))
- **Natural Language Commanding via Program Synthesis**, `arXiv, 2306.03460`, [arxiv](http://arxiv.org/abs/2306.03460v1), [pdf](http://arxiv.org/pdf/2306.03460v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=4911123869793861169&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Apurva Gandhi, Thong Q. Nguyen, Huitian Jiao, Robert Steen, Ameya Bhatawdekar*
- **Think Before You Act: Decision Transformers with Internal Working Memory**, `arXiv, 2305.16338`, [arxiv](http://arxiv.org/abs/2305.16338v1), [pdf](http://arxiv.org/pdf/2305.16338v1.pdf), cication: [**-1**](None)

	 *Jikun Kang, Romain Laroche, Xindi Yuan, Adam Trischler, Xue Liu, Jie Fu* ¬∑ ([qbitai](https://www.qbitai.com/2023/06/59572.html))
- **Visual Programming: Compositional visual reasoning without training**, `arXiv, 2211.11559`, [arxiv](http://arxiv.org/abs/2211.11559v1), [pdf](http://arxiv.org/pdf/2211.11559v1.pdf), cication: [**-1**](None)

	 *Tanmay Gupta, Aniruddha Kembhavi*

### Other
- [Chat ÂêëÂ∑¶ÔºåAgent ÂêëÂè≥ - Áü•‰πé](https://zhuanlan.zhihu.com/p/662704254)
- [ÂäüËÉΩË∂ÖÂÖ®ÁöÑAI AgentsÂºÄÊ∫êÂ∫ìÊù•‰∫ÜÔºåËÉΩÂÜôÂ∞èËØ¥ÔºåËøòËÉΩÂΩìÂØºË¥≠„ÄÅÈîÄÂîÆ | Êú∫Âô®‰πãÂøÉ](https://www.jiqizhixin.com/articles/2023-09-21-2)
- [AIÈù©Êñ∞‰πãË∑ØÔºö14ÁØáAI AgentsËÆ∫ÊñáÔºåÊé¢ËÆ®‰∫∫Â∑•Êô∫ËÉΩÊú™Êù•](https://mp.weixin.qq.com/s?__biz=MzIyMzk1MDE3Nw==&mid=2247609813&idx=2&sn=668922b98c7891b569a78ff4c2a32280)
- [Êï∞Â≠óË∫´‰ªΩÊô∫ËÉΩ‰ΩìÁöÑÂü∫Êú¨ÂéüÁêÜÂèäÂ∫îÁî®ÂâçÊôØÂ±ïÊúõ](https://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&mid=2247611020&idx=1&sn=eeea2012a2bcfe541a138c9a4c42b837)

## AutoGPT
- [**open-interpreter**](https://github.com/KillianLucas/open-interpreter) - KillianLucas ![Star](https://img.shields.io/github/stars/KillianLucas/open-interpreter.svg?style=social&label=Star)

	 *OpenAI's Code Interpreter in your terminal, running locally.*
- [**ChatDev**](https://github.com/OpenBMB/ChatDev) - OpenBMB ![Star](https://img.shields.io/github/stars/OpenBMB/ChatDev.svg?style=social&label=Star)

	 *Create Customized Software using Natural Language Idea (through Multi-Agent Collaboration)*
- [**gpt-researcher**](https://github.com/assafelovic/gpt-researcher) - assafelovic ![Star](https://img.shields.io/github/stars/assafelovic/gpt-researcher.svg?style=social&label=Star)

	 *GPT based autonomous agent that does online comprehensive research on any given topic*
- [**gpt-llm-trainer**](https://github.com/mshumer/gpt-llm-trainer) - mshumer ![Star](https://img.shields.io/github/stars/mshumer/gpt-llm-trainer.svg?style=social&label=Star)

	 ¬∑ ([qbitai](https://www.qbitai.com/2023/08/78155.html))
- [**MetaGPT**](https://github.com/geekan/MetaGPT) - geekan ![Star](https://img.shields.io/github/stars/geekan/MetaGPT.svg?style=social&label=Star)

	 *The Multi-Agent Meta Programming Framework: Given one line Requirement, return PRD, Design, Tasks, Repo | Â§öÊô∫ËÉΩ‰ΩìÂÖÉÁºñÁ®ãÊ°ÜÊû∂ÔºöÁªôÂÆöËÄÅÊùøÈúÄÊ±ÇÔºåËæìÂá∫‰∫ßÂìÅÊñáÊ°£„ÄÅÊû∂ÊûÑËÆæËÆ°„ÄÅ‰ªªÂä°ÂàóË°®„ÄÅ‰ª£Á†Å*
- [Toward Actionable Generative AI](https://blog.salesforceairesearch.com/large-action-models/)
- [**PromptAppGPT**](https://github.com/mleoking/PromptAppGPT) - mleoking ![Star](https://img.shields.io/github/stars/mleoking/PromptAppGPT.svg?style=social&label=Star)

	 *A rapid prompt app development framework based on GPT* ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652343982&idx=3&sn=b9a4a664b29431b19b4077217f27d768))
- **Responsible Task Automation: Empowering Large Language Models as
  Responsible Task Automators**, `arXiv, 2306.01242`, [arxiv](http://arxiv.org/abs/2306.01242v1), [pdf](http://arxiv.org/pdf/2306.01242v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=15333508948166383051&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhizheng Zhang, Xiaoyi Zhang, Wenxuan Xie, Yan Lu* ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-06-22-3))
- **Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions**, `arXiv, 2306.02224`, [arxiv](http://arxiv.org/abs/2306.02224v1), [pdf](http://arxiv.org/pdf/2306.02224v1.pdf), cication: [**10**](https://scholar.google.com/scholar?cites=10760126869775216861&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Hui Yang, Sifu Yue, Yunzhong He* ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652340210&idx=4&sn=faa472d3af543a7fc36e3eb5f13bc081))
- **CAMEL: Communicative Agents for "Mind" Exploration of Large Language
  Model Society**, `arXiv, 2303.17760`, [arxiv](http://arxiv.org/abs/2303.17760v2), [pdf](http://arxiv.org/pdf/2303.17760v2.pdf), cication: [**-1**](None)

	 *Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem*
- **Language Models can Solve Computer Tasks**, `arXiv, 2303.17491`, [arxiv](http://arxiv.org/abs/2303.17491v2), [pdf](http://arxiv.org/pdf/2303.17491v2.pdf), cication: [**50**](https://scholar.google.com/scholar?cites=2552584892380879541&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Geunwoo Kim, Pierre Baldi, Stephen McAleer*
- [**SuperAGI**](https://github.com/TransformerOptimus/SuperAGI) - TransformerOptimus ![Star](https://img.shields.io/github/stars/TransformerOptimus/SuperAGI.svg?style=social&label=Star)

	 *<‚ö°Ô∏è> SuperAGI - A dev-first open source autonomous AI agent framework. Enabling developers to build, manage & run useful autonomous agents quickly and reliably.*
- [**babyagi**](https://github.com/yoheinakajima/babyagi) - yoheinakajima ![Star](https://img.shields.io/github/stars/yoheinakajima/babyagi.svg?style=social&label=Star)
- **Re3: Generating Longer Stories With Recursive Reprompting and Revision**, `arXiv, 2210.06774`, [arxiv](http://arxiv.org/abs/2210.06774v3), [pdf](http://arxiv.org/pdf/2210.06774v3.pdf), cication: [**55**](https://scholar.google.com/scholar?cites=12913281204520727323&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Kevin Yang, Yuandong Tian, Nanyun Peng, Dan Klein*
- **Language Models as Zero-Shot Planners: Extracting Actionable Knowledge
  for Embodied Agents**, `ICML, 2022`, [arxiv](http://arxiv.org/abs/2201.07207v2), [pdf](http://arxiv.org/pdf/2201.07207v2.pdf), cication: [**341**](https://scholar.google.com/scholar?cites=11998123682359381476&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch* ¬∑ ([huangwl18.github](https://huangwl18.github.io/language-planner))

### Other
- [Godmode.space](https://godmode.space/?ref=futuretools.io)

	 ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652349067&idx=1&sn=99bd053f20c8821a5c821dc2e7a972dc)) ¬∑ ([cognosys](https://www.cognosys.ai/)) ¬∑ ([doanythingmachine](https://www.doanythingmachine.com/))
- [AgentGPT](https://agentgpt.reworkd.ai/)

## Augmented LLM
- **ControlLLM: Augment Language Models with Tools by Searching on Graphs**, `arXiv, 2310.17796`, [arxiv](http://arxiv.org/abs/2310.17796v2), [pdf](http://arxiv.org/pdf/2310.17796v2.pdf), cication: [**-1**](None)

	 *Zhaoyang Liu, Zeqiang Lai, Zhangwei Gao, Erfei Cui, Zhiheng Li, Xizhou Zhu, Lewei Lu, Qifeng Chen, Yu Qiao, Jifeng Dai*
- **Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language**, `arXiv, 2204.00598`, [arxiv](http://arxiv.org/abs/2204.00598v2), [pdf](http://arxiv.org/pdf/2204.00598v2.pdf), cication: [**202**](https://scholar.google.com/scholar?cites=17485588102904105060&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Andy Zeng, Maria Attarian, Brian Ichter, Krzysztof Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas Sindhwani* ¬∑ ([socraticmodels.github](https://socraticmodels.github.io/#code))
- **Understanding Retrieval Augmentation for Long-Form Question Answering**, `arXiv, 2310.12150`, [arxiv](http://arxiv.org/abs/2310.12150v1), [pdf](http://arxiv.org/pdf/2310.12150v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=13555030950984354517&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Hung-Ting Chen, Fangyuan Xu, Shane Arora, Eunsol Choi*
- **Reward-Augmented Decoding: Efficient Controlled Text Generation With a
  Unidirectional Reward Model**, `arXiv, 2310.09520`, [arxiv](http://arxiv.org/abs/2310.09520v3), [pdf](http://arxiv.org/pdf/2310.09520v3.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=5740043218256432933&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Haikang Deng, Colin Raffel*
- **RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective
  Augmentation**, `arXiv, 2310.04408`, [arxiv](http://arxiv.org/abs/2310.04408v1), [pdf](http://arxiv.org/pdf/2310.04408v1.pdf), cication: [**-1**](None)

	 *Fangyuan Xu, Weijia Shi, Eunsol Choi*
- **InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining**, `arXiv, 2310.07713`, [arxiv](http://arxiv.org/abs/2310.07713v1), [pdf](http://arxiv.org/pdf/2310.07713v1.pdf), cication: [**-1**](None)

	 *Boxin Wang, Wei Ping, Lawrence McAfee, Peng Xu, Bo Li, Mohammad Shoeybi, Bryan Catanzaro*
- **RA-DIT: Retrieval-Augmented Dual Instruction Tuning**, `arXiv, 2310.01352`, [arxiv](http://arxiv.org/abs/2310.01352v3), [pdf](http://arxiv.org/pdf/2310.01352v3.pdf), cication: [**-1**](None)

	 *Xi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Rich James, Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis*

- **Retroformer: Retrospective Large Language Agents with Policy Gradient
  Optimization**, `arXiv, 2308.02151`, [arxiv](http://arxiv.org/abs/2308.02151v1), [pdf](http://arxiv.org/pdf/2308.02151v1.pdf), cication: [**6**](https://scholar.google.com/scholar?cites=15394605017148461219&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit*
- **Meta-training with Demonstration Retrieval for Efficient Few-shot
  Learning**, `arXiv, 2307.00119`, [arxiv](http://arxiv.org/abs/2307.00119v1), [pdf](http://arxiv.org/pdf/2307.00119v1.pdf), cication: [**-1**](None)

	 *Aaron Mueller, Kanika Narang, Lambert Mathias, Qifan Wang, Hamed Firooz*
- **AVIS: Autonomous Visual Information Seeking with Large Language Model
  Agent**, `arXiv, 2306.08129`, [arxiv](http://arxiv.org/abs/2306.08129v3), [pdf](http://arxiv.org/pdf/2306.08129v3.pdf), cication: [**-1**](None)

	 *Ziniu Hu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A Ross, Cordelia Schmid, Alireza Fathi* ¬∑ ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652368752&idx=4&sn=4028750afec250eb722937fe934b80b1))
- **Modular Visual Question Answering via Code Generation**, `arXiv, 2306.05392`, [arxiv](http://arxiv.org/abs/2306.05392v1), [pdf](http://arxiv.org/pdf/2306.05392v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=10338616761686111271&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Sanjay Subramanian, Medhini Narasimhan, Kushal Khangaonkar, Kevin Yang, Arsha Nagrani, Cordelia Schmid, Andy Zeng, Trevor Darrell, Dan Klein*
- **Reimagining Retrieval Augmented Language Models for Answering Queries**, `arXiv, 2306.01061`, [arxiv](http://arxiv.org/abs/2306.01061v1), [pdf](http://arxiv.org/pdf/2306.01061v1.pdf), cication: [**-1**](None)

	 *Wang-Chiew Tan, Yuliang Li, Pedro Rodriguez, Richard James, Xi Victoria Lin, Alon Halevy, Scott Yih*

### Other
- [Èôà‰∏πÁê¶ACLÂ≠¶ÊúØÊä•ÂëäÊù•‰∫ÜÔºÅËØ¶Ëß£Â§ßÊ®°Âûã„ÄåÂ§ñÊåÇ„ÄçÊï∞ÊçÆÂ∫ì7Â§ßÊñπÂêë3Â§ßÊåëÊàòÔºå3Â∞èÊó∂Âπ≤Ë¥ßÊª°Êª° | ÈáèÂ≠ê‰Ωç](https://www.qbitai.com/2023/07/67259.html)
## Web browsing
- [**webglm**](https://github.com/thudm/webglm) - thudm ![Star](https://img.shields.io/github/stars/thudm/webglm.svg?style=social&label=Star)

	 *WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023)*
- **FreshLLMs: Refreshing Large Language Models with Search Engine
  Augmentation**, `arXiv, 2310.03214`, [arxiv](http://arxiv.org/abs/2310.03214v1), [pdf](http://arxiv.org/pdf/2310.03214v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=5401685431323690843&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry Wei, Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny Zhou, Quoc Le* ¬∑ ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-10-10-2))
- **GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone
  GUI Navigation**, `arXiv, 2311.07562`, [arxiv](http://arxiv.org/abs/2311.07562v1), [pdf](http://arxiv.org/pdf/2311.07562v1.pdf), cication: [**-1**](None)

	 *An Yan, Zhengyuan Yang, Wanrong Zhu, Kevin Lin, Linjie Li, Jianfeng Wang, Jianwei Yang, Yiwu Zhong, Julian McAuley, Jianfeng Gao* ¬∑ ([MM-Navigator](https://github.com/zzxslp/MM-Navigator) - zzxslp) ![Star](https://img.shields.io/github/stars/zzxslp/MM-Navigator.svg?style=social&label=Star)

	 ¬∑ ([qbitai](https://www.qbitai.com/2023/11/98316.html))
- [**vimGPT**](https://github.com/ishan0102/vimGPT) - ishan0102 ![Star](https://img.shields.io/github/stars/ishan0102/vimGPT.svg?style=social&label=Star)

	 *Browse the web with GPT-4V and Vimium*
- **A Real-World WebAgent with Planning, Long Context Understanding, and
  Program Synthesis**, `arXiv, 2307.12856`, [arxiv](http://arxiv.org/abs/2307.12856v3), [pdf](http://arxiv.org/pdf/2307.12856v3.pdf), cication: [**13**](https://scholar.google.com/scholar?cites=11247435352141794384&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, Aleksandra Faust*
- [**WebGLM**](https://github.com/THUDM/WebGLM) - THUDM ![Star](https://img.shields.io/github/stars/THUDM/WebGLM.svg?style=social&label=Star)

	 *WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023)*
- [WebArena: A Realistic Web Environment for Building Autonomous Agents](https://webarena.dev/#try-it-yourself)

	 ¬∑ ([t](https://twitter.com/shuyanzhxyc/status/1683917253597855744))

### Other
- [GPT-4VÂ≠¶‰ºöÁî®ÈîÆÈº†‰∏äÁΩëÔºå‰∫∫Á±ªÁúºÁùÅÁùÅÁúãÁùÄÂÆÉÂèëÂ∏ñÁé©Ê∏∏Êàè | ÈáèÂ≠ê‰Ωç](https://www.qbitai.com/2023/11/95456.html)

## Retrieval agumented generation
- [**gpt-crawler**](https://github.com/BuilderIO/gpt-crawler) - BuilderIO ![Star](https://img.shields.io/github/stars/BuilderIO/gpt-crawler.svg?style=social&label=Star)

	 *Crawl a site to generate knowledge files to create your own custom GPT from a URL*
- [**Langchain-Chatchat**](https://github.com/chatchat-space/Langchain-Chatchat) - chatchat-space ![Star](https://img.shields.io/github/stars/chatchat-space/Langchain-Chatchat.svg?style=social&label=Star)

	 *Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langchain ‰∏é ChatGLM Á≠âËØ≠Ë®ÄÊ®°ÂûãÁöÑÊú¨Âú∞Áü•ËØÜÂ∫ìÈóÆÁ≠î | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM) QA app with langchain*
- [**privateGPT**](https://github.com/imartinez/privateGPT) - imartinez ![Star](https://img.shields.io/github/stars/imartinez/privateGPT.svg?style=social&label=Star)

	 *Interact with your documents using the power of GPT, 100% privately, no data leaks*

- **KITAB: Evaluating LLMs on Constraint Satisfaction for Information
  Retrieval**, `arXiv, 2310.15511`, [arxiv](http://arxiv.org/abs/2310.15511v1), [pdf](http://arxiv.org/pdf/2310.15511v1.pdf), cication: [**-1**](None)

	 *Marah I Abdin, Suriya Gunasekar, Varun Chandrasekaran, Jerry Li, Mert Yuksekgonul, Rahee Ghosh Peshawaria, Ranjita Naik, Besmira Nushi*
- [**Langchain-Chatchat**](https://github.com/chatchat-space/Langchain-Chatchat) - chatchat-space ![Star](https://img.shields.io/github/stars/chatchat-space/Langchain-Chatchat.svg?style=social&label=Star)

	 *Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langchain ‰∏é ChatGLM Á≠âËØ≠Ë®ÄÊ®°ÂûãÁöÑÊú¨Âú∞Áü•ËØÜÂ∫ìÈóÆÁ≠î | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM) QA app with langchain*
- [**DocsGPT**](https://github.com/arc53/DocsGPT) - arc53 ![Star](https://img.shields.io/github/stars/arc53/DocsGPT.svg?style=social&label=Star)

	 *GPT-powered chat for documentation, chat with your documents* ¬∑ ([qbitai](https://www.qbitai.com/2023/10/87996.html))
- **LMDX: Language Model-based Document Information Extraction and
  Localization**, `arXiv, 2309.10952`, [arxiv](http://arxiv.org/abs/2309.10952v1), [pdf](http://arxiv.org/pdf/2309.10952v1.pdf), cication: [**-1**](None)

	 *Vincent Perot, Kai Kang, Florian Luisier, Guolong Su, Xiaoyu Sun, Ramya Sree Boppana, Zilong Wang, Jiaqi Mu, Hao Zhang, Nan Hua*
- **PDFTriage: Question Answering over Long, Structured Documents**, `arXiv, 2309.08872`, [arxiv](http://arxiv.org/abs/2309.08872v2), [pdf](http://arxiv.org/pdf/2309.08872v2.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=851640409311189815&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Jon Saad-Falcon, Joe Barrow, Alexa Siu, Ani Nenkova, David Seunghyun Yoon, Ryan A. Rossi, Franck Dernoncourt*
- [**sec-insights**](https://github.com/run-llama/sec-insights) - run-llama ![Star](https://img.shields.io/github/stars/run-llama/sec-insights.svg?style=social&label=Star)

	 *A real world full-stack application using LlamaIndex*
- [**simplyretrieve**](https://github.com/rcgai/simplyretrieve) - rcgai ![Star](https://img.shields.io/github/stars/rcgai/simplyretrieve.svg?style=social&label=Star)

	 *An Easy-to-use Private and Lightweight Retrieval-Centric Generative AI Tool. Create chat tool with your documents and open-source LLMs, highly customizable.*
- [**FastGPT**](https://github.com/labring/FastGPT) - labring ![Star](https://img.shields.io/github/stars/labring/FastGPT.svg?style=social&label=Star)

	 *A platform that uses the OpenAI API to quickly build an AI knowledge base, supporting many-to-many relationships.*
- [**factool**](https://github.com/gair-nlp/factool) - gair-nlp ![Star](https://img.shields.io/github/stars/gair-nlp/factool.svg?style=social&label=Star)

	 *A fact-checking tool that detects factual errors.*
- [**Llama-2-Open-Source-LLM-CPU-Inference**](https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference) - kennethleungty ![Star](https://img.shields.io/github/stars/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference.svg?style=social&label=Star)

	 *Running Llama 2 and other Open-Source LLMs on CPU Inference Locally for Document¬†Q&A*
- [**danswer**](https://github.com/danswer-ai/danswer) - danswer-ai ![Star](https://img.shields.io/github/stars/danswer-ai/danswer.svg?style=social&label=Star)

	 *Ask Questions in natural language and get Answers backed by private sources. Connects to tools like Slack, GitHub, Confluence, etc.*
- [**quivr**](https://github.com/StanGirard/quivr) - StanGirard ![Star](https://img.shields.io/github/stars/StanGirard/quivr.svg?style=social&label=Star)

	 *üß† Dump all your files and thoughts into your private GenerativeAI Second Brain and chat with it üß†*
- [**chatgpt-retrieval**](https://github.com/techleadhd/chatgpt-retrieval) - techleadhd ![Star](https://img.shields.io/github/stars/techleadhd/chatgpt-retrieval.svg?style=social&label=Star)
- [**localGPT**](https://github.com/PromtEngineer/localGPT) - PromtEngineer ![Star](https://img.shields.io/github/stars/PromtEngineer/localGPT.svg?style=social&label=Star)

	 *Chat with your documents on your local device using GPT models. No data leaves your device and 100% private.*
- [**privateGPT**](https://github.com/imartinez/privateGPT) - imartinez ![Star](https://img.shields.io/github/stars/imartinez/privateGPT.svg?style=social&label=Star)

	 *Interact privately with your documents using the power of GPT, 100% privately, no data leaks*

### Other
- [ÈóÆÁ≠îÂú∫ÊôØÂ∏∏Áî®Â§ßÊ®°ÂûãËß£ÂÜ≥ÊñπÊ°à](https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247494688&idx=2&sn=d871403a80a7fcf656ce0100f266f939)

## Code Interpreter
- [**open-interpreter**](https://github.com/KillianLucas/open-interpreter) - KillianLucas ![Star](https://img.shields.io/github/stars/KillianLucas/open-interpreter.svg?style=social&label=Star)

	 *OpenAI's Code Interpreter in your terminal, running locally*

## GPTs
- [**gpts-works**](https://github.com/all-in-aigc/gpts-works) - all-in-aigc ![Star](https://img.shields.io/github/stars/all-in-aigc/gpts-works.svg?style=social&label=Star)

	 *A Third-party GPTs store*
- [**gpt-crawler**](https://github.com/BuilderIO/gpt-crawler) - BuilderIO ![Star](https://img.shields.io/github/stars/BuilderIO/gpt-crawler.svg?style=social&label=Star)

	 *Crawl a site to generate knowledge files to create your own custom GPT from a URL*
- [**Awesome-GPTs**](https://github.com/ai-boost/Awesome-GPTs) - ai-boost ![Star](https://img.shields.io/github/stars/ai-boost/Awesome-GPTs.svg?style=social&label=Star)

	 *Curated list of awesome GPTs üëç.*
- [**Awesome-GPT-Agents**](https://github.com/fr0gger/Awesome-GPT-Agents) - fr0gger ![Star](https://img.shields.io/github/stars/fr0gger/Awesome-GPT-Agents.svg?style=social&label=Star)

	 *A curated list of GPT agents for cybersecurity*
- [**Awesome-GPT-Store**](https://github.com/Anil-matcha/Awesome-GPT-Store) - Anil-matcha ![Star](https://img.shields.io/github/stars/Anil-matcha/Awesome-GPT-Store.svg?style=social&label=Star)

	 *A collection of major GPTS available in public*
- [**awesome-gpts**](https://github.com/taranjeet/awesome-gpts) - taranjeet ![Star](https://img.shields.io/github/stars/taranjeet/awesome-gpts.svg?style=social&label=Star)

	 *Collection of all the GPTs created by the community*
- [**opengpts**](https://github.com/langchain-ai/opengpts) - langchain-ai ![Star](https://img.shields.io/github/stars/langchain-ai/opengpts.svg?style=social&label=Star)

### Plugins
- [GPT-4Ë∞ÉÁî®Êèí‰ª∂40Ê¨°ÈÉΩÊ≤°ÊàêÂäüÔºåÊûúÊñ≠ÊîæÂºÉÔºåÊó†ÊïàË∞ÉÁî®„ÄÅÊãíÁªùÂõûÁ≠îÊó∂ÊúâÂèëÁîü | Êú∫Âô®‰πãÂøÉ](https://www.jiqizhixin.com/articles/2023-08-12)
### Other 
- [ÂêÑË∑ØÂ§ßÁ•ûÁåÆÂá∫Ëá™ÂÆö‰πâGPTÔºå24Â∞èÊó∂Top 9ÂêçÂçïÂú®Ëøô | Êú∫Âô®‰πãÂøÉ](https://www.jiqizhixin.com/articles/2023-11-13-13)

## Evaluation
- **BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents**, `arXiv, 2308.05960`, [arxiv](http://arxiv.org/abs/2308.05960v1), [pdf](http://arxiv.org/pdf/2308.05960v1.pdf), cication: [**7**](https://scholar.google.com/scholar?cites=7461840210213149264&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit* ¬∑ ([BOLAA](https://github.com/salesforce/BOLAA) - salesforce) ![Star](https://img.shields.io/github/stars/salesforce/BOLAA.svg?style=social&label=Star)
- [**mlagentbench**](https://github.com/snap-stanford/mlagentbench) - snap-stanford ![Star](https://img.shields.io/github/stars/snap-stanford/mlagentbench.svg?style=social&label=Star)
- [**smartplay**](https://github.com/microsoft/smartplay) - microsoft ![Star](https://img.shields.io/github/stars/microsoft/smartplay.svg?style=social&label=Star)

	 *SmartPlay is a benchmark for Large Language Models (LLMs). It is designed to be easy to use, and to provide a wide variety of games to test agents on.*
- **AgentBench: Evaluating LLMs as Agents**, `arXiv, 2308.03688`, [arxiv](http://arxiv.org/abs/2308.03688v2), [pdf](http://arxiv.org/pdf/2308.03688v2.pdf), cication: [**9**](https://scholar.google.com/scholar?cites=17298865796446863019&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang*

## Other
- [Rapidly build an application in Gradio power by a Generative AI Agent | Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/rapidly-build-an-application-in-gradio-power-by-a-generative-ai-agent)

## Extra reference
- [**llm-agent-survey**](https://github.com/paitesanshi/llm-agent-survey) - paitesanshi ![Star](https://img.shields.io/github/stars/paitesanshi/llm-agent-survey.svg?style=social&label=Star)
- [**awesome-ai-agents**](https://github.com/e2b-dev/awesome-ai-agents) - e2b-dev ![Star](https://img.shields.io/github/stars/e2b-dev/awesome-ai-agents.svg?style=social&label=Star)

	 *A list of AI autonomous agents*
- [**generative_agents**](https://github.com/joonspk-research/generative_agents) - joonspk-research ![Star](https://img.shields.io/github/stars/joonspk-research/generative_agents.svg?style=social&label=Star)

	 *Generative Agents: Interactive Simulacra of Human Behavior*