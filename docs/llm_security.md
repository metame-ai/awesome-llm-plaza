# LLM Security

- [LLM Security](#llm-security) 
  - [Survey](#survey)
  - [LLM Security](#llm-security)
  - [Red Team](#red-team)
  - [Projects](#projects)
  - [Misc](#misc)


## Survey


## LLM Security

- **Safeguard Fine-Tuned LLMs Through Pre- and Post-Tuning Model Merging**, `arXiv, 2412.19512`, [arxiv](http://arxiv.org/abs/2412.19512v1), [pdf](http://arxiv.org/pdf/2412.19512v1.pdf), cication: [**-1**](None) 

	 *Hua Farn, Hsuan Su, Shachi H Kumar, ..., Shang-Tse Chen, Hung-yi Lee*
- [Alignment faking in large language models](https://www.anthropic.com/research/alignment-faking) 

	 · ([assets.anthropic](https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf))
- [Deliberative alignment: reasoning enables safer language models](https://openai.com/index/deliberative-alignment/) 
- [Best-of-N Jailbreaking](https://jplhughes.github.io/bon-jailbreaking/) 

	 · ([𝕏](https://x.com/AnthropicAI/status/1867608917595107443))
- **Granite Guardian**, `arXiv, 2412.07724`, [arxiv](http://arxiv.org/abs/2412.07724v1), [pdf](http://arxiv.org/pdf/2412.07724v1.pdf), cication: [**-1**](None) 

	 *Inkit Padhi, Manish Nagireddy, Giandomenico Cornacchia, ..., Kush R. Varshney, Prasanna Sattigeri* · ([granite-guardian](https://github.com/ibm-granite/granite-guardian) - ibm-granite) ![Star](https://img.shields.io/github/stars/ibm-granite/granite-guardian.svg?style=social&label=Star)
- **Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding 
  Conversations**, `arXiv, 2411.10414`, [arxiv](http://arxiv.org/abs/2411.10414v1), [pdf](http://arxiv.org/pdf/2411.10414v1.pdf), cication: [**-1**](None) 

	 *Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, ..., Kartikeya Upasani, Mahesh Pasupuleti* · ([llama](https://www.llama.com/trust-and-safety/)) · ([llama-recipes](https://github.com/meta-llama/llama-recipes/tree/main/recipes/responsible_ai/llama_guard) - meta-llama) ![Star](https://img.shields.io/github/stars/meta-llama/llama-recipes.svg?style=social&label=Star)
- **Building Trust: Foundations of Security, Safety and Transparency in AI**, `arXiv, 2411.12275`, [arxiv](http://arxiv.org/abs/2411.12275v1), [pdf](http://arxiv.org/pdf/2411.12275v1.pdf), cication: [**-1**](None) 

	 *Huzaifa Sidhpurwala, Garth Mollett, Emily Fox, ..., Mark Bestavros, Huamin Chen*
- **Rapid Response: Mitigating LLM Jailbreaks with a Few Examples**, `arXiv, 2411.07494`, [arxiv](http://arxiv.org/abs/2411.07494v1), [pdf](http://arxiv.org/pdf/2411.07494v1.pdf), cication: [**-1**](None) 

	 *Alwin Peng, Julian Michael, Henry Sleight, ..., Ethan Perez, Mrinank Sharma* · ([𝕏](https://x.com/AnthropicAI/status/1856752093945540673)) · ([rapidresponsebench](https://github.com/rapidresponsebench/rapidresponsebench) - rapidresponsebench) ![Star](https://img.shields.io/github/stars/rapidresponsebench/rapidresponsebench.svg?style=social&label=Star)
- **AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents**, `arXiv, 2410.09024`, [arxiv](http://arxiv.org/abs/2410.09024v2), [pdf](http://arxiv.org/pdf/2410.09024v2.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=2401564792328774425&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Maksym Andriushchenko, Alexandra Souly, Mateusz Dziemian, ..., Yarin Gal, Xander Davies*

## Red Team

- [Advancing red teaming with people and AI](https://openai.com/index/advancing-red-teaming-with-people-and-ai/) 

## Projects

- [**Awesome-LLM-Safety-Papers**](https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers) - tjunlp-lab ![Star](https://img.shields.io/github/stars/tjunlp-lab/Awesome-LLM-Safety-Papers.svg?style=social&label=Star) 
- [**PromptJailbreakManual**](https://github.com/Acmesec/PromptJailbreakManual) - Acmesec ![Star](https://img.shields.io/github/stars/Acmesec/PromptJailbreakManual.svg?style=social&label=Star) 
- [**CS-Eval**](https://github.com/CS-EVAL/CS-Eval) - CS-EVAL ![Star](https://img.shields.io/github/stars/CS-EVAL/CS-Eval.svg?style=social&label=Star) 
- [**garak**](https://github.com/NVIDIA/garak) - NVIDIA ![Star](https://img.shields.io/github/stars/NVIDIA/garak.svg?style=social&label=Star) 
- [**arch**](https://github.com/katanemo/arch) - katanemo ![Star](https://img.shields.io/github/stars/katanemo/arch.svg?style=social&label=Star) 

	 · ([x](https://x.com/salman_paracha/status/1848374304196719047))

## Misc
## Misc
- [Open Source AI Can Help America Lead in AI and Strengthen Global Security](https://about.fb.com/news/2024/11/open-source-ai-america-global-security/) 