# Embodied AI

- [Embodied AI](#embodied-ai) 
  - [Survey](#survey)
  - [Embodied AI](#embodied-ai-1)
  - [Robotics](#robotics)
  - [Humanoids](#humanoids)
  - [Projects](#projects)
  - [Misc](#misc)


## Survey

- **Neural Fields in Robotics: A Survey**, `arXiv, 2410.20220`, [arxiv](http://arxiv.org/abs/2410.20220v1), [pdf](http://arxiv.org/pdf/2410.20220v1.pdf), cication: [**-1**](None) 

	 *Muhammad Zubair Irshad, Mauro Comi, Yen-Chen Lin, ..., Zsolt Kira, Jonathan Tremblay* 路 ([robonerf.github](https://robonerf.github.io/))

## Embodied AI

- **OmniManip: Towards General Robotic Manipulation via Object-Centric 
  Interaction Primitives as Spatial Constraints**, `arXiv, 2501.03841`, [arxiv](http://arxiv.org/abs/2501.03841v1), [pdf](http://arxiv.org/pdf/2501.03841v1.pdf), cication: [**-1**](None) 

	 *Mingjie Pan, Jiyao Zhang, Tianshu Wu, ..., Wenlong Gao, Hao Dong* 路 ([omnimanip.github](https://omnimanip.github.io/))
- **Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous 
  Sensors via Language Grounding**, `arXiv, 2501.04693`, [arxiv](http://arxiv.org/abs/2501.04693v1), [pdf](http://arxiv.org/pdf/2501.04693v1.pdf), cication: [**-1**](None) 

	 *Joshua Jones, Oier Mees, Carmelo Sferrazza, ..., Pieter Abbeel, Sergey Levine*
-  **EnerVerse: Envisioning Embodied Future Space for Robotics Manipulation**, `arXiv, 2501.01895`, [arxiv](http://arxiv.org/abs/2501.01895v1), [pdf](http://arxiv.org/pdf/2501.01895v1.pdf), cication: [**-1**](None) 

	 *Siyuan Huang, Liliang Chen, Pengfei Zhou, ..., Maoqing Yao, Guanghui Ren* 路 ([sites.google](https://sites.google.com/view/enerverse))
- **Towards Generalist Robot Policies: What Matters in Building 
  Vision-Language-Action Models**, `arXiv, 2412.14058`, [arxiv](http://arxiv.org/abs/2412.14058v3), [pdf](http://arxiv.org/pdf/2412.14058v3.pdf), cication: [**-1**](None) 

	 *Xinghang Li, Peiyan Li, Minghuan Liu, ..., Hanbo Zhang, Huaping Liu*
- **Code-as-Monitor: Constraint-aware Visual Programming for Reactive and 
  Proactive Robotic Failure Detection**, `arXiv, 2412.04455`, [arxiv](http://arxiv.org/abs/2412.04455v2), [pdf](http://arxiv.org/pdf/2412.04455v2.pdf), cication: [**-1**](None) 

	 *Enshen Zhou, Qi Su, Cheng Chi, ..., Lu Sheng, He Wang* 路 ([zhoues.github](https://zhoues.github.io/Code-as-Monitor/))
- **Moto: Latent Motion Token as the Bridging Language for Robot 
  Manipulation**, `arXiv, 2412.04445`, [arxiv](http://arxiv.org/abs/2412.04445v1), [pdf](http://arxiv.org/pdf/2412.04445v1.pdf), cication: [**-1**](None) 

	 *Yi Chen, Yuying Ge, Yizhuo Li, ..., Ying Shan, Xihui Liu* 路 ([chenyi99.github](https://chenyi99.github.io/moto/)) 路 ([Moto](https://github.com/TencentARC/Moto) - TencentARC) ![Star](https://img.shields.io/github/stars/TencentARC/Moto.svg?style=social&label=Star)
-  **Unraveling the Complexity of Memory in RL Agents: an Approach for 
  Classification and Evaluation**, `arXiv, 2412.06531`, [arxiv](http://arxiv.org/abs/2412.06531v1), [pdf](http://arxiv.org/pdf/2412.06531v1.pdf), cication: [**-1**](None) 

	 *Egor Cherepanov, Nikita Kachaev, Artem Zholus, ..., Alexey K. Kovalev, Aleksandr I. Panov*
- **Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making**, `arXiv, 2410.07166`, [arxiv](http://arxiv.org/abs/2410.07166v2), [pdf](http://arxiv.org/pdf/2410.07166v2.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=2488405281591567279&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Manling Li, Shiyu Zhao, Qineng Wang, ..., Jiayuan Mao, Jiajun Wu* 路 ([embodied-agent-interface.github](https://embodied-agent-interface.github.io/)) 路 ([embodied-agent-eval](https://github.com/embodied-agent-eval/embodied-agent-eval) - embodied-agent-eval) ![Star](https://img.shields.io/github/stars/embodied-agent-eval/embodied-agent-eval.svg?style=social&label=Star) 路 ([](https://x.com/manlingli_/status/1854041025146404897?s=46))
- [foundation models for the physical world.](https://perceptron.inc/) 
- **DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for 
  Efficient Robot Execution**, `arXiv, 2411.02359`, [arxiv](http://arxiv.org/abs/2411.02359v1), [pdf](http://arxiv.org/pdf/2411.02359v1.pdf), cication: [**-1**](None) 

	 *Yang Yue, Yulin Wang, Bingyi Kang, ..., Jiashi Feng, Gao Huang* 路 ([DeeR-VLA](https://github.com/yueyang130/DeeR-VLA) - yueyang130) ![Star](https://img.shields.io/github/stars/yueyang130/DeeR-VLA.svg?style=social&label=Star)
- **DynaMem: Online Dynamic Spatio-Semantic Memory for Open World Mobile 
  Manipulation**, `arXiv, 2411.04999`, [arxiv](http://arxiv.org/abs/2411.04999v1), [pdf](http://arxiv.org/pdf/2411.04999v1.pdf), cication: [**-1**](None) 

	 *Peiqi Liu, Zhanqiu Guo, Mohit Warke, ..., Nur Muhammad Mahi Shafiullah, Lerrel Pinto* 路 ([dynamem.github](https://dynamem.github.io/))
- **A Large Recurrent Action Model: xLSTM enables Fast Inference for 
  Robotics Tasks**, `arXiv, 2410.22391`, [arxiv](http://arxiv.org/abs/2410.22391v1), [pdf](http://arxiv.org/pdf/2410.22391v1.pdf), cication: [**-1**](None)

	 *Thomas Schmied, Thomas Adler, Vihang Patil, ..., Razvan Pascanu, Sepp Hochreiter* 路 ([arxiv](https://arxiv.org/abs/2410.22391)) 路 ([huggingface](https://huggingface.co/ml-jku)) 路 ([LRAM](https://github.com/ml-jku/LRAM) - ml-jku) ![Star](https://img.shields.io/github/stars/ml-jku/LRAM.svg?style=social&label=Star)
- **VLMimic: Vision Language Models are Visual Imitation Learner for 
  Fine-grained Actions**, `arXiv, 2410.20927`, [arxiv](http://arxiv.org/abs/2410.20927v2), [pdf](http://arxiv.org/pdf/2410.20927v2.pdf), cication: [**-1**](None)

	 *Guanyan Chen, Meiling Wang, Te Cui, ..., Yi Yang, Yufeng Yue*
- **VidEgoThink: Assessing Egocentric Video Understanding Capabilities for 
  Embodied AI**, `arXiv, 2410.11623`, [arxiv](http://arxiv.org/abs/2410.11623v1), [pdf](http://arxiv.org/pdf/2410.11623v1.pdf), cication: [**-1**](None)

	 *Sijie Cheng, Kechen Fang, Yangyang Yu, ..., Lei Han, Yang Liu*

## Robotics

- [CS 294-277, Robots That Learn (Fall 2024)](http://robots-that-learn.github.io/) 
- [Introducing AgiBot World, the first large-scale robotic learning dataset designed to advance multi-purpose robotic policies.](https://agibot-world.com/) 

	 路 ([Agibot-World](https://github.com/OpenDriveLab/Agibot-World) - OpenDriveLab) ![Star](https://img.shields.io/github/stars/OpenDriveLab/Agibot-World.svg?style=social&label=Star)
- [**openpilot**](https://github.com/commaai/openpilot) - commaai ![Star](https://img.shields.io/github/stars/commaai/openpilot.svg?style=social&label=Star) 
- [**flow_matching**](https://github.com/HRI-EU/flow_matching) - HRI-EU ![Star](https://img.shields.io/github/stars/HRI-EU/flow_matching.svg?style=social&label=Star) 
- [fastest, most precise, and most capable hand control setup](https://x.com/RemiCadene/status/1868210029985513959)   
- **GRAPE: Generalizing Robot Policy via Preference Alignment**, `arXiv, 2411.19309`, [arxiv](http://arxiv.org/abs/2411.19309v1), [pdf](http://arxiv.org/pdf/2411.19309v1.pdf), cication: [**-1**](None) 

	 *Zijian Zhang, Kaiyuan Zheng, Zhaorun Chen, ..., Dieter Fox, Huaxiu Yao* 路 ([grape-vla.github](https://grape-vla.github.io/))
- **Soft Robotic Dynamic In-Hand Pen Spinning**, `arXiv, 2411.12734`, [arxiv](http://arxiv.org/abs/2411.12734v1), [pdf](http://arxiv.org/pdf/2411.12734v1.pdf), cication: [**-1**](None) 

	 *Yunchao Yao, Uksang Yoo, Jean Oh, ..., Christopher G. Atkeson, Jeffrey Ichnowski* 路 ([soft-spin.github](https://soft-spin.github.io/))
- [trained surgical robots through video-based imitation learning to match human surgeon skill levels](https://x.com/adcock_brett/status/1858194256680079674)   
- [DEEP Robotics shared a new video of their new commercially available robot dog](https://x.com/adcock_brett/status/1858194279056744876)   
- **HOVER: Versatile Neural Whole-Body Controller for Humanoid Robots**, `arXiv, 2410.21229`, [arxiv](http://arxiv.org/abs/2410.21229v1), [pdf](http://arxiv.org/pdf/2410.21229v1.pdf), cication: [**-1**](None) 

	 *Tairan He, Wenli Xiao, Toru Lin, ..., Linxi Fan, Yuke Zhu* 路 ([x](https://x.com/DrJimFan/status/1851643431803830551)) 路 ([hover-versatile-humanoid.github](https://hover-versatile-humanoid.github.io/))
- **DexMimicGen: Automated Data Generation for Bimanual Dexterous 
  Manipulation via Imitation Learning**, `arXiv, 2410.24185`, [arxiv](http://arxiv.org/abs/2410.24185v1), [pdf](http://arxiv.org/pdf/2410.24185v1.pdf), cication: [**-1**](None)

	 *Zhenyu Jiang, Yuqi Xie, Kevin Lin, ..., Linxi Fan, Yuke Zhu* 路 ([dexmimicgen.github](https://dexmimicgen.github.io/)) 路 ([twitter](https://twitter.com/SteveTod1998/status/1852365700372832707))
- [Advancing embodied AI through progress in touch perception, dexterity, and human-robot interaction](https://ai.meta.com/blog/fair-robotics-open-source/) 

	 路 ([x](https://x.com/AIatMeta/status/1852019804292682200))
- [what is the largest public dataset of robot expert demonstrations across diverse manipulations tasks, constrained to a single form factor?](https://x.com/ericjang11/status/1851987666000101596)   
- [AI-assisted multi-arm robot for apple picking](https://buttondown.com/ainews/archive/ainews-github-copilot-strikes-back-3402/) 

	 路 ([v.redd](https://v.redd.it/552w8berqhxd1))
- [**moss-robot-arms**](https://github.com/jess-moss/moss-robot-arms) - jess-moss ![Star](https://img.shields.io/github/stars/jess-moss/moss-robot-arms.svg?style=social&label=Star) 
- **Language-Model-Assisted Bi-Level Programming for Reward Learning from 
  Internet Videos**, `arXiv, 2410.09286`, [arxiv](http://arxiv.org/abs/2410.09286v1), [pdf](http://arxiv.org/pdf/2410.09286v1.pdf), cication: [**-1**](None)

	 *Harsh Mahesheka, Zhixian Xie, Zhaoran Wang, ..., Wanxin Jin*

## Humanoids

- [**unitree_rl_gym**](https://github.com/unitreerobotics/unitree_rl_gym) - unitreerobotics ![Star](https://img.shields.io/github/stars/unitreerobotics/unitree_rl_gym.svg?style=social&label=Star) 
- [Boston Dynamics showcased Atlas autonomously transferring engine covers using ML vision for object detection and localization](https://x.com/adcock_brett/status/1853120940651024503)   
- [EngineAI unveiled SE01, a humanoid robot achieving natural walking through advanced joint modules and neural networks.](https://x.com/adcock_brett/status/1850569193365676202)   
- [Introducing Torso, a bimanual android actuated with artificial muscles.](https://x.com/clonerobotics/status/1849181515022053845)   
- [CooHOI, a learning-based framework designed for the cooperative transportation of objects by multiple humanoid robots.](https://x.com/WinstonGu_/status/1848393460849799439)   
- **CooHOI: Learning Cooperative Human-Object Interaction with Manipulated 
  Object Dynamics**, `arXiv, 2406.14558`, [arxiv](http://arxiv.org/abs/2406.14558v2), [pdf](http://arxiv.org/pdf/2406.14558v2.pdf), cication: [**-1**](None)

	 *Jiawei Gao, Ziqin Wang, Zeqi Xiao, ..., Jifeng Dai, Jiangmiao Pang* 路 ([gao-jiawei](https://gao-jiawei.com/Research/CooHOI/))

## Projects

- [**Genesis**](https://github.com/Genesis-Embodied-AI/Genesis) - Genesis-Embodied-AI ![Star](https://img.shields.io/github/stars/Genesis-Embodied-AI/Genesis.svg?style=social&label=Star) 

## Misc