# LLM Alignment

- [LLM Alignment](#llm-alignment) 
  - [Survey](#survey)
  - [LLM Alignment](#llm-alignment-1)
  - [Projects](#projects)
  - [Misc](#misc)


## Survey


## LLM Alignment

- **Alignment faking in large language models**, `arXiv, 2412.14093`, [arxiv](http://arxiv.org/abs/2412.14093v2), [pdf](http://arxiv.org/pdf/2412.14093v2.pdf), cication: [**-1**](None) 

	 *Ryan Greenblatt, Carson Denison, Benjamin Wright, ..., Samuel R. Bowman, Evan Hubinger* 路 ([alignment_faking_public](https://github.com/redwoodresearch/alignment_faking_public) - redwoodresearch) ![Star](https://img.shields.io/github/stars/redwoodresearch/alignment_faking_public.svg?style=social&label=Star)
-  **RobustFT: Robust Supervised Fine-tuning for Large Language Models under 
  Noisy Response**, `arXiv, 2412.14922`, [arxiv](http://arxiv.org/abs/2412.14922v1), [pdf](http://arxiv.org/pdf/2412.14922v1.pdf), cication: [**-1**](None) 

	 *Junyu Luo, Xiao Luo, Kaize Ding, ..., Zhiping Xiao, Ming Zhang* 路 ([RobustFT](https://github.com/luo-junyu/RobustFT) - luo-junyu) ![Star](https://img.shields.io/github/stars/luo-junyu/RobustFT.svg?style=social&label=Star)
- **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better 
  Reasoning in SLMs**, `arXiv, 2412.08347`, [arxiv](http://arxiv.org/abs/2412.08347v1), [pdf](http://arxiv.org/pdf/2412.08347v1.pdf), cication: [**-1**](None) 

	 *Sultan Alrashed*
- [Alignment faking in large language models](https://www.anthropic.com/research/alignment-faking) 

	 路 ([assets.anthropic](https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf))
- [[10 Dec 2024, NeurIPS // Infer] Post-training for applications](https://docs.google.com/presentation/d/1LWHbtz74GwKSGYZKyBVUtcyvp8lgYOi5EVpMnVDXBPs/edit) 

	 路 ([](https://x.com/natolambert/status/1866197250239541350))
-  **KTO: Model Alignment as Prospect Theoretic Optimization**, `arXiv, 2402.01306`, [arxiv](http://arxiv.org/abs/2402.01306v4), [pdf](http://arxiv.org/pdf/2402.01306v4.pdf), cication: [**-1**](None) 

	 *Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, ..., Dan Jurafsky, Douwe Kiela*
- **Does your data spark joy? Performance gains from domain upsampling at 
  the end of training**, `arXiv, 2406.03476`, [arxiv](http://arxiv.org/abs/2406.03476v1), [pdf](http://arxiv.org/pdf/2406.03476v1.pdf), cication: [**-1**](None) 

	 *Cody Blakeney, Mansheej Paul, Brett W. Larsen, ..., Sean Owen, Jonathan Frankle*
- [Metas Post-Training Pipeline for Llama 3.1](https://medium.com/@jkabrit/metas-post-training-pipeline-for-llama-3-1-e6777801c0a1) 
- [WizardArena: Post-training Large Language Models via Simulated Offline Chatbot Aren](https://openreview.net/forum?id=VHva3d836i) 

	 路 ([arxiv](https://arxiv.org/abs/2407.10627v1))
- **Rewarding Chatbots for Real-World Engagement with Millions of Users**, `arXiv, 2303.06135`, [arxiv](http://arxiv.org/abs/2303.06135v2), [pdf](http://arxiv.org/pdf/2303.06135v2.pdf), cication: [**-1**](None) 

	 *Robert Irvine, Douglas Boubert, Vyas Raina, ..., Thomas Rialan, William Beauchamp*
- **IOPO: Empowering LLMs with Complex Instruction Following via 
  Input-Output Preference Optimization**, `arXiv, 2411.06208`, [arxiv](http://arxiv.org/abs/2411.06208v1), [pdf](http://arxiv.org/pdf/2411.06208v1.pdf), cication: [**-1**](None) 

	 *Xinghua Zhang, Haiyang Yu, Cheng Fu, ..., Fei Huang, Yongbin Li*
- **Aligning Large Language Models via Self-Steering Optimization**, `arXiv, 2410.17131`, [arxiv](http://arxiv.org/abs/2410.17131v1), [pdf](http://arxiv.org/pdf/2410.17131v1.pdf), cication: [**-1**](None) 

	 *Hao Xiang, Bowen Yu, Hongyu Lin, ..., Jingren Zhou, Junyang Lin*
- **LOGO -- Long cOntext aliGnment via efficient preference Optimization**, `arXiv, 2410.18533`, [arxiv](http://arxiv.org/abs/2410.18533v1), [pdf](http://arxiv.org/pdf/2410.18533v1.pdf), cication: [**-1**](None) 

	 *Zecheng Tang, Zechen Sun, Juntao Li, ..., Qiaoming Zhu, Min Zhang*
- **Baichuan Alignment Technical Report**, `arXiv, 2410.14940`, [arxiv](http://arxiv.org/abs/2410.14940v1), [pdf](http://arxiv.org/pdf/2410.14940v1.pdf), cication: [**-1**](None) 

	 *Mingan Lin, Fan Yang, Yanjun Shen, ..., Zenan Zhou, Weipeng Chen* 路 ([huggingface](https://huggingface.co/PKU-Baichuan-MLSystemLab/Llama3-PBM-Nova-70B))

## Projects


## Misc
## Misc
- [How language model post-training is done today](https://www.youtube.com/)  :clapper: 