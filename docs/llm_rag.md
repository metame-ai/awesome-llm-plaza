# LLM Rag

- [LLM Rag](#llm-rag) 
  - [Survey](#survey)
  - [RAG](#rag)
  - [Multi Modal](#multi-modal)
  - [Embedding](#embedding)
  - [Evaluation](#evaluation)
  - [Database](#database)
  - [Projects](#projects)
  - [Products](#products)
  - [Misc](#misc)
  - [Vector Database](#vector-database)


## Survey


## RAG

-  **HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge 
  in RAG Systems**, `arXiv, 2411.02959`, [arxiv](http://arxiv.org/abs/2411.02959v1), [pdf](http://arxiv.org/pdf/2411.02959v1.pdf), cication: [**-1**](None) 

	 *Jiejun Tan, Zhicheng Dou, Wen Wang, ..., Weipeng Chen, Ji-Rong Wen*
- **M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page 
  Multi-document Understanding**, `arXiv, 2411.04952`, [arxiv](http://arxiv.org/abs/2411.04952v1), [pdf](http://arxiv.org/pdf/2411.04952v1.pdf), cication: [**-1**](None) 

	 *Jaemin Cho, Debanjan Mahata, Ozan Irsoy, ..., Yujie He, Mohit Bansal* 路 ([m3docrag.github](https://m3docrag.github.io/))
- **In Defense of RAG in the Era of Long-Context Language Models**, `arXiv, 2409.01666`, [arxiv](http://arxiv.org/abs/2409.01666v1), [pdf](http://arxiv.org/pdf/2409.01666v1.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=3261789221345650637&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Tan Yu, Anbang Xu, Rama Akkiraju* 路 ([zyphra](https://www.zyphra.com/post/reaching-1b-context-length-with-rag))
- **Toward General Instruction-Following Alignment for Retrieval-Augmented 
  Generation**, `arXiv, 2410.09584`, [arxiv](http://arxiv.org/abs/2410.09584v1), [pdf](http://arxiv.org/pdf/2410.09584v1.pdf), cication: [**-1**](None)

	 *Guanting Dong, Xiaoshuai Song, Yutao Zhu, ..., Zhicheng Dou, Ji-Rong Wen* 路 ([FollowRAG.github](https://FollowRAG.github.io)) 路 ([arxiv](https://arxiv.org/pdf/2410.09584)) 路 ([FollowRAG](https://github.com/dongguanting/FollowRAG) - dongguanting) ![Star](https://img.shields.io/github/stars/dongguanting/FollowRAG.svg?style=social&label=Star) 路 ([huggingface](https://huggingface.co/datasets/dongguanting/VIF-RAG-QA-110K))
- **Meta-Chunking: Learning Efficient Text Segmentation via Logical 
  Perception**, `arXiv, 2410.12788`, [arxiv](http://arxiv.org/abs/2410.12788v1), [pdf](http://arxiv.org/pdf/2410.12788v1.pdf), cication: [**-1**](None)

	 *Jihao Zhao, Zhiyuan Ji, Pengnian Qi, ..., Feiyu Xiong, Zhiyu Li* 路 ([Meta-Chunking](https://github.com/IAAR-Shanghai/Meta-Chunking) - IAAR-Shanghai) ![Star](https://img.shields.io/github/stars/IAAR-Shanghai/Meta-Chunking.svg?style=social&label=Star) 路 ([arxiv](https://arxiv.org/abs/2410.12788))
- **Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free**, `arXiv, 2410.10814`, [arxiv](http://arxiv.org/abs/2410.10814v2), [pdf](http://arxiv.org/pdf/2410.10814v2.pdf), cication: [**-1**](None) 

	 *Ziyue Li, Tianyi Zhou* 路 ([MoE-Embedding](https://github.com/tianyi-lab/MoE-Embedding) - tianyi-lab) ![Star](https://img.shields.io/github/stars/tianyi-lab/MoE-Embedding.svg?style=social&label=Star)

## Multi Modal

- **Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial 
  Applications**, `arXiv, 2410.21943`, [arxiv](http://arxiv.org/abs/2410.21943v1), [pdf](http://arxiv.org/pdf/2410.21943v1.pdf), cication: [**-1**](None)

	 *Monica Riedler, Stefan Langer* 路 ([x](https://x.com/omarsar0/status/1851479149690642456))
- **VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality 
  Documents**, `arXiv, 2410.10594`, [arxiv](http://arxiv.org/abs/2410.10594v1), [pdf](http://arxiv.org/pdf/2410.10594v1.pdf), cication: [**-1**](None)

	 *Shi Yu, Chaoyue Tang, Bokai Xu, ..., Zhiyuan Liu, Maosong Sun*
- [Introducing Multimodal Embed 3: Powering AI Search](https://cohere.com/blog/multimodal-embed-3) 
- **MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language 
  Models**, `arXiv, 2410.13085`, [arxiv](http://arxiv.org/abs/2410.13085v1), [pdf](http://arxiv.org/pdf/2410.13085v1.pdf), cication: [**-1**](None)

	 *Peng Xia, Kangyu Zhu, Haoran Li, ..., James Zou, Huaxiu Yao*

## Embedding


## Evaluation

- **Long Context RAG Performance of Large Language Models**, `arXiv, 2411.03538`, [arxiv](http://arxiv.org/abs/2411.03538v1), [pdf](http://arxiv.org/pdf/2411.03538v1.pdf), cication: [**-1**](None) 

	 *Quinn Leng, Jacob Portes, Sam Havens, ..., Matei Zaharia, Michael Carbin*
- **CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation 
  Generation**, `arXiv, 2410.23090`, [arxiv](http://arxiv.org/abs/2410.23090v1), [pdf](http://arxiv.org/pdf/2410.23090v1.pdf), cication: [**-1**](None)

	 *Yiruo Cheng, Kelong Mao, Ziliang Zhao, ..., Ji-Rong Wen, Zhicheng Dou* 路 ([CORAL](https://github.com/Ariya12138/CORAL) - Ariya12138) ![Star](https://img.shields.io/github/stars/Ariya12138/CORAL.svg?style=social&label=Star)

## Database


## Projects

-  [**RAGViz**](https://github.com/cxcscmu/RAGViz) - cxcscmu ![Star](https://img.shields.io/github/stars/cxcscmu/RAGViz.svg?style=social&label=Star) 

	 路 ([youtube](https://www.youtube.com/embed/cTAbuTu6ur4?si=-uZ2AyNLx-5p8MZC))
- [**pgai**](https://github.com/timescale/pgai) - timescale ![Star](https://img.shields.io/github/stars/timescale/pgai.svg?style=social&label=Star) 
- [Contextual RAG from Anthropic](https://x.com/togethercompute/status/1850939031301099919)   

	 路 ([together-cookbook](https://github.com/togethercomputer/together-cookbook/blob/main/Open_Contextual_RAG.ipynb) - togethercomputer) ![Star](https://img.shields.io/github/stars/togethercomputer/together-cookbook.svg?style=social&label=Star)
- [**AutoRAG**](https://github.com/Marker-Inc-Korea/AutoRAG) - Marker-Inc-Korea ![Star](https://img.shields.io/github/stars/Marker-Inc-Korea/AutoRAG.svg?style=social&label=Star) 
- [**KAG**](https://github.com/OpenSPG/KAG) - OpenSPG ![Star](https://img.shields.io/github/stars/OpenSPG/KAG.svg?style=social&label=Star) 

	 *Knowledge Augmented Generation*

## Products


## Misc

- [What is Agentic RAG](https://weaviate.io/blog/what-is-agentic-rag) 

	 路 ([](https://x.com/helloiamleonie/status/1853832634448687451))
- [Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge](https://huggingface.co/blog/digital-green-llm-judge)   

## Vector Database