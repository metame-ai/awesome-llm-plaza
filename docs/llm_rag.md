# LLM Rag

- [LLM Rag](#llm-rag) 
  - [Survey](#survey)
  - [RAG](#rag)
  - [Multi Modal](#multi-modal)
  - [Embedding](#embedding)
  - [Evaluation](#evaluation)
  - [Database](#database)
  - [Projects](#projects)
  - [Products](#products)
  - [Misc](#misc)
  - [Vector Database](#vector-database)


## Survey

- **Ask in Any Modality: A Comprehensive Survey on Multimodal 
  Retrieval-Augmented Generation**, `arXiv, 2502.08826`, [arxiv](http://arxiv.org/abs/2502.08826v2), [pdf](http://arxiv.org/pdf/2502.08826v2.pdf), cication: [**-1**](None) 

	 *Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, ..., Mahdieh Soleymani Baghshah, Ehsaneddin Asgari* · ([Multimodal-RAG-Survey](https://github.com/llm-lab-org/Multimodal-RAG-Survey) - llm-lab-org) ![Star](https://img.shields.io/github/stars/llm-lab-org/Multimodal-RAG-Survey.svg?style=social&label=Star)
- **Towards Trustworthy Retrieval Augmented Generation for Large Language 
  Models: A Survey**, `arXiv, 2502.06872`, [arxiv](http://arxiv.org/abs/2502.06872v1), [pdf](http://arxiv.org/pdf/2502.06872v1.pdf), cication: [**-1**](None) 

	 *Bo Ni, Zheyuan Liu, Leyao Wang, ..., Meng Jiang, Tyler Derr*

## RAG

- **UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse 
  Modalities and Granularities**, `arXiv, 2504.20734`, [arxiv](http://arxiv.org/abs/2504.20734v2), [pdf](http://arxiv.org/pdf/2504.20734v2.pdf), cication: [**-1**](None) 

	 *Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, ..., Jinheon Baek, Sung Ju Hwang* · ([universalrag.github](https://universalrag.github.io/))
- **ReasonIR: Training Retrievers for Reasoning Tasks**, `arXiv, 2504.20595`, [arxiv](http://arxiv.org/abs/2504.20595v1), [pdf](http://arxiv.org/pdf/2504.20595v1.pdf), cication: [**-1**](None) 

	 *Rulin Shao, Rui Qiao, Varsha Kishore, ..., Pang Wei Koh, Luke Zettlemoyer*
- 🌟 **NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes**, `arXiv, 2504.11544`, [arxiv](http://arxiv.org/abs/2504.11544v1), [pdf](http://arxiv.org/pdf/2504.11544v1.pdf), cication: [**-1**](None) 

	 *Tianyang Xu, Haojie Zheng, Chengze Li, ..., Ruoxi Chen, Lichao Sun* · ([NodeRAG.](https://github.com/Terry-Xu-666/NodeRAG.) - Terry-Xu-666) ![Star](https://img.shields.io/github/stars/Terry-Xu-666/NodeRAG..svg?style=social&label=Star)
- **RouterRetriever: Routing over a Mixture of Expert Embedding Models**, `arXiv, 2409.02685`, [arxiv](http://arxiv.org/abs/2409.02685v2), [pdf](http://arxiv.org/pdf/2409.02685v2.pdf), cication: [**-1**](None) 

	 *Hyunji Lee, Luca Soldaini, Arman Cohan, ..., Minjoon Seo, Kyle Lo* · ([𝕏](https://x.com/hyunji_amy_lee/status/1895880862375559641))
- **Enhancing Financial Time-Series Forecasting with Retrieval-Augmented 
  Large Language Models**, `arXiv, 2502.05878`, [arxiv](http://arxiv.org/abs/2502.05878v2), [pdf](http://arxiv.org/pdf/2502.05878v2.pdf), cication: [**-1**](None) 

	 *Mengxi Xiao, Zihao Jiang, Lingfei Qian, ..., Sophia Ananiadou, Qianqian Xie* · ([huggingface](https://huggingface.co/TheFinAI.))
- **SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of 
  Large Language Model**, `arXiv, 2501.18636`, [arxiv](http://arxiv.org/abs/2501.18636v1), [pdf](http://arxiv.org/pdf/2501.18636v1.pdf), cication: [**-1**](None) 

	 *Xun Liang, Simin Niu, Zhiyu Li, ..., Mengwei Wang, Jiawei Yang* · ([SafeRAG](https://github.com/IAAR-Shanghai/SafeRAG) - IAAR-Shanghai) ![Star](https://img.shields.io/github/stars/IAAR-Shanghai/SafeRAG.svg?style=social&label=Star)
- **SelfCite: Self-Supervised Alignment for Context Attribution in Large 
  Language Models**, `arXiv, 2502.09604`, [arxiv](http://arxiv.org/abs/2502.09604v1), [pdf](http://arxiv.org/pdf/2502.09604v1.pdf), cication: [**-1**](None) 

	 *Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, ..., Shang-Wen Li, Wen-tau Yih*
- **Chain-of-Retrieval Augmented Generation**, `arXiv, 2501.14342`, [arxiv](http://arxiv.org/abs/2501.14342v1), [pdf](http://arxiv.org/pdf/2501.14342v1.pdf), cication: [**-1**](None) 

	 *Liang Wang, Haonan Chen, Nan Yang, ..., Zhicheng Dou, Furu Wei*
- **MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**, `arXiv, 2501.06713`, [arxiv](http://arxiv.org/abs/2501.06713v2), [pdf](http://arxiv.org/pdf/2501.06713v2.pdf), cication: [**-1**](None) 

	 *Tianyu Fan, Jingyuan Wang, Xubin Ren, ..., Chao Huang* · ([MiniRAG](https://github.com/HKUDS/MiniRAG) - HKUDS) ![Star](https://img.shields.io/github/stars/HKUDS/MiniRAG.svg?style=social&label=Star)
- 🌟 **OmniThink: Expanding Knowledge Boundaries in Machine Writing through 
  Thinking**, `arXiv, 2501.09751`, [arxiv](http://arxiv.org/abs/2501.09751v1), [pdf](http://arxiv.org/pdf/2501.09751v1.pdf), cication: [**-1**](None) 

	 *Zekun Xi, Wenbiao Yin, Jizhan Fang, ..., Fei Huang, Huajun Chen* · ([zjunlp.github](https://zjunlp.github.io/project/OmniThink/))
- [Knowledge Models Combine Retrieval with Generation: An Introduction to RAG](https://llm-class.github.io/speakers.html) 
- **Personalized Graph-Based Retrieval for Large Language Models**, `arXiv, 2501.02157`, [arxiv](http://arxiv.org/abs/2501.02157v1), [pdf](http://arxiv.org/pdf/2501.02157v1.pdf), cication: [**-1**](None) 

	 *Steven Au, Cameron J. Dimacali, Ojasmitha Pedirappagari, ..., Ryan A. Rossi, Nesreen K. Ahmed*
- **GeAR: Generation Augmented Retrieval**, `arXiv, 2501.02772`, [arxiv](http://arxiv.org/abs/2501.02772v1), [pdf](http://arxiv.org/pdf/2501.02772v1.pdf), cication: [**-1**](None) 

	 *Haoyu Liu, Shaohan Huang, Jianfeng Liu, ..., Furu Wei, Qi Zhang*
- **Don't Do RAG: When Cache-Augmented Generation is All You Need for 
  Knowledge Tasks**, `arXiv, 2412.15605`, [arxiv](http://arxiv.org/abs/2412.15605v1), [pdf](http://arxiv.org/pdf/2412.15605v1.pdf), cication: [**-1**](None) 

	 *Brian J Chan, Chao-Ting Chen, Jui-Hung Cheng, ..., Hen-Hsen Huang* · ([cag](https://github.com/hhhuang/cag?tab=readme-ov-file) - hhhuang) ![Star](https://img.shields.io/github/stars/hhhuang/cag.svg?style=social&label=Star)
- **Long Context vs. RAG for LLMs: An Evaluation and Revisits**, `arXiv, 2501.01880`, [arxiv](http://arxiv.org/abs/2501.01880v1), [pdf](http://arxiv.org/pdf/2501.01880v1.pdf), cication: [**-1**](None) 

	 *Xinze Li, Yixin Cao, Yubo Ma, ..., Aixin Sun*
- **SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic 
  Retrieval**, `arXiv, 2412.15443`, [arxiv](http://arxiv.org/abs/2412.15443v1), [pdf](http://arxiv.org/pdf/2412.15443v1.pdf), cication: [**-1**](None) 

	 *Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, ..., Vinija Jain, Divya Chaudhary*
- [GemmaEmbed is a dense-vector embedding model, trained especially for retrieval.](https://huggingface.co/google/Gemma-Embeddings-v1.0)  🤗 
- 🌟 **Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for 
  Fast, Memory Efficient, and Long Context Finetuning and Inference**, `arXiv, 2412.13663`, [arxiv](http://arxiv.org/abs/2412.13663v2), [pdf](http://arxiv.org/pdf/2412.13663v2.pdf), cication: [**-1**](None) 

	 *Benjamin Warner, Antoine Chaffin, Benjamin Clavié, ..., Jeremy Howard, Iacopo Poli* · ([huggingface](https://huggingface.co/blog/modernbert)) · ([𝕏](https://x.com/jeremyphoward/status/1869786023963832509?s=46))
- **Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language 
  Models**, `arXiv, 2411.19443`, [arxiv](http://arxiv.org/abs/2411.19443v1), [pdf](http://arxiv.org/pdf/2411.19443v1.pdf), cication: [**-1**](None) 

	 *Tian Yu, Shaolei Zhang, Yang Feng* · ([Auto-RAG](https://github.com/ictnlp/Auto-RAG) - ictnlp) ![Star](https://img.shields.io/github/stars/ictnlp/Auto-RAG.svg?style=social&label=Star)
- [NV-Embed-v2, a generalist embedding model that ranks No. 1 on the Massive Text Embedding Benchmark (MTEB benchmark)](https://huggingface.co/nvidia/NV-Embed-v2)  🤗 

	 · ([arxiv](https://arxiv.org/pdf/2405.17428))
- [Jina CLIP v2: Multilingual Multimodal Embeddings for Texts and Images](https://huggingface.co/jinaai/jina-clip-v2)  🤗 

	 · ([huggingface](https://huggingface.co/jinaai/jina-clip-v2))
- **Long Term Memory: The Foundation of AI Self-Evolution**, `arXiv, 2410.15665`, [arxiv](http://arxiv.org/abs/2410.15665v2), [pdf](http://arxiv.org/pdf/2410.15665v2.pdf), cication: [**-1**](None) 

	 *Xun Jiang, Feng Li, Han Zhao, ..., Mengdi Wang, Tianqiao Chen* · ([𝕏](https://x.com/TankaChat/status/1857272126358880267))
- [Binary vector embeddings are so cool](https://emschwartz.me/binary-vector-embeddings-are-so-cool/) 
- 🌟 **HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge 
  in RAG Systems**, `arXiv, 2411.02959`, [arxiv](http://arxiv.org/abs/2411.02959v1), [pdf](http://arxiv.org/pdf/2411.02959v1.pdf), cication: [**-1**](None) 

	 *Jiejun Tan, Zhicheng Dou, Wen Wang, ..., Weipeng Chen, Ji-Rong Wen*
- **M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page 
  Multi-document Understanding**, `arXiv, 2411.04952`, [arxiv](http://arxiv.org/abs/2411.04952v1), [pdf](http://arxiv.org/pdf/2411.04952v1.pdf), cication: [**-1**](None) 

	 *Jaemin Cho, Debanjan Mahata, Ozan Irsoy, ..., Yujie He, Mohit Bansal* · ([m3docrag.github](https://m3docrag.github.io/))
- **In Defense of RAG in the Era of Long-Context Language Models**, `arXiv, 2409.01666`, [arxiv](http://arxiv.org/abs/2409.01666v1), [pdf](http://arxiv.org/pdf/2409.01666v1.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=3261789221345650637&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Tan Yu, Anbang Xu, Rama Akkiraju* · ([zyphra](https://www.zyphra.com/post/reaching-1b-context-length-with-rag))
- **Toward General Instruction-Following Alignment for Retrieval-Augmented 
  Generation**, `arXiv, 2410.09584`, [arxiv](http://arxiv.org/abs/2410.09584v1), [pdf](http://arxiv.org/pdf/2410.09584v1.pdf), cication: [**-1**](None)

	 *Guanting Dong, Xiaoshuai Song, Yutao Zhu, ..., Zhicheng Dou, Ji-Rong Wen* · ([FollowRAG.github](https://FollowRAG.github.io)) · ([arxiv](https://arxiv.org/pdf/2410.09584)) · ([FollowRAG](https://github.com/dongguanting/FollowRAG) - dongguanting) ![Star](https://img.shields.io/github/stars/dongguanting/FollowRAG.svg?style=social&label=Star) · ([huggingface](https://huggingface.co/datasets/dongguanting/VIF-RAG-QA-110K))
- **Meta-Chunking: Learning Efficient Text Segmentation via Logical 
  Perception**, `arXiv, 2410.12788`, [arxiv](http://arxiv.org/abs/2410.12788v1), [pdf](http://arxiv.org/pdf/2410.12788v1.pdf), cication: [**-1**](None)

	 *Jihao Zhao, Zhiyuan Ji, Pengnian Qi, ..., Feiyu Xiong, Zhiyu Li* · ([Meta-Chunking](https://github.com/IAAR-Shanghai/Meta-Chunking) - IAAR-Shanghai) ![Star](https://img.shields.io/github/stars/IAAR-Shanghai/Meta-Chunking.svg?style=social&label=Star) · ([arxiv](https://arxiv.org/abs/2410.12788))
- **Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free**, `arXiv, 2410.10814`, [arxiv](http://arxiv.org/abs/2410.10814v2), [pdf](http://arxiv.org/pdf/2410.10814v2.pdf), cication: [**-1**](None) 

	 *Ziyue Li, Tianyi Zhou* · ([MoE-Embedding](https://github.com/tianyi-lab/MoE-Embedding) - tianyi-lab) ![Star](https://img.shields.io/github/stars/tianyi-lab/MoE-Embedding.svg?style=social&label=Star)

## Multi Modal

- 🌟 **VideoRAG: Retrieval-Augmented Generation over Video Corpus**, `arXiv, 2501.05874`, [arxiv](http://arxiv.org/abs/2501.05874v1), [pdf](http://arxiv.org/pdf/2501.05874v1.pdf), cication: [**-1**](None) 

	 *Soyeong Jeong, Kangsan Kim, Jinheon Baek, ..., Sung Ju Hwang* · ([huggingface](https://huggingface.co/blog/Kseniase/html-multimodal-agentic-rag)) · ([𝕏](https://x.com/TheTuringPost/status/1878932305177453037))
- [Visual Document Retrieval Goes Multilingual](https://huggingface.co/blog/vdr-2b-multilingual)  🤗 

	 · ([𝕏](https://x.com/_philschmid/status/1877778889566494843))
- [MM-Embed, an extension of NV-Embed-v1 with multimodal retrieval capability.](https://huggingface.co/nvidia/MM-Embed)  🤗 
- **Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial 
  Applications**, `arXiv, 2410.21943`, [arxiv](http://arxiv.org/abs/2410.21943v1), [pdf](http://arxiv.org/pdf/2410.21943v1.pdf), cication: [**-1**](None)

	 *Monica Riedler, Stefan Langer* · ([x](https://x.com/omarsar0/status/1851479149690642456))
- **VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality 
  Documents**, `arXiv, 2410.10594`, [arxiv](http://arxiv.org/abs/2410.10594v1), [pdf](http://arxiv.org/pdf/2410.10594v1.pdf), cication: [**-1**](None)

	 *Shi Yu, Chaoyue Tang, Bokai Xu, ..., Zhiyuan Liu, Maosong Sun*
- [Introducing Multimodal Embed 3: Powering AI Search](https://cohere.com/blog/multimodal-embed-3) 
- **MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language 
  Models**, `arXiv, 2410.13085`, [arxiv](http://arxiv.org/abs/2410.13085v1), [pdf](http://arxiv.org/pdf/2410.13085v1.pdf), cication: [**-1**](None)

	 *Peng Xia, Kangyu Zhu, Haoran Li, ..., James Zou, Huaxiu Yao*

## Embedding

- **Breaking the Modality Barrier: Universal Embedding Learning with 
  Multimodal LLMs**, `arXiv, 2504.17432`, [arxiv](http://arxiv.org/abs/2504.17432v1), [pdf](http://arxiv.org/pdf/2504.17432v1.pdf), cication: [**-1**](None) 

	 *Tiancheng Gu, Kaicheng Yang, Ziyong Feng, ..., Weidong Cai, Jiankang Deng*
- [nomic-embed-text-v2-moe: Multilingual Mixture of Experts Text Embeddings](https://huggingface.co/nomic-ai/nomic-embed-text-v2-moe)  🤗 
- [Train 400x faster Static Embedding Models with Sentence Transformers](https://huggingface.co/blog/static-embeddings)  🤗 

	 · ([𝕏](https://x.com/tomaarsen/status/1879547342346666450))

## Evaluation

- [How to Evaluate Document Extraction](https://x.com/LangChainAI/status/1885012449352704123)  𝕏 
- **WebWalker: Benchmarking LLMs in Web Traversal**, `arXiv, 2501.07572`, [arxiv](http://arxiv.org/abs/2501.07572v2), [pdf](http://arxiv.org/pdf/2501.07572v2.pdf), cication: [**-1**](None) 

	 *Jialong Wu, Wenbiao Yin, Yong Jiang, ..., Pengjun Xie, Fei Huang* · ([WebWalker](https://github.com/Alibaba-NLP/WebWalker) - Alibaba-NLP) ![Star](https://img.shields.io/github/stars/Alibaba-NLP/WebWalker.svg?style=social&label=Star)
- 🌟 **MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents**, `arXiv, 2501.08828`, [arxiv](http://arxiv.org/abs/2501.08828v1), [pdf](http://arxiv.org/pdf/2501.08828v1.pdf), cication: [**-1**](None) 

	 *Kuicai Dong, Yujing Chang, Xin Deik Goh, ..., Ruiming Tang, Yong Liu*
- **OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in 
  Financial Domain**, `arXiv, 2412.13018`, [arxiv](http://arxiv.org/abs/2412.13018v1), [pdf](http://arxiv.org/pdf/2412.13018v1.pdf), cication: [**-1**](None) 

	 *Shuting Wang, Jiejun Tan, Zhicheng Dou, ..., Ji-Rong Wen* · ([OmniEval](https://github.com/RUC-NLPIR/OmniEval) - RUC-NLPIR) ![Star](https://img.shields.io/github/stars/RUC-NLPIR/OmniEval.svg?style=social&label=Star)
- **Long Context RAG Performance of Large Language Models**, `arXiv, 2411.03538`, [arxiv](http://arxiv.org/abs/2411.03538v1), [pdf](http://arxiv.org/pdf/2411.03538v1.pdf), cication: [**-1**](None) 

	 *Quinn Leng, Jacob Portes, Sam Havens, ..., Matei Zaharia, Michael Carbin*
- **CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation 
  Generation**, `arXiv, 2410.23090`, [arxiv](http://arxiv.org/abs/2410.23090v1), [pdf](http://arxiv.org/pdf/2410.23090v1.pdf), cication: [**-1**](None)

	 *Yiruo Cheng, Kelong Mao, Ziliang Zhao, ..., Ji-Rong Wen, Zhicheng Dou* · ([CORAL](https://github.com/Ariya12138/CORAL) - Ariya12138) ![Star](https://img.shields.io/github/stars/Ariya12138/CORAL.svg?style=social&label=Star)

## Database


## Projects

- [**Finetune-Bench-RAG**](https://github.com/Pints-AI/Finetune-Bench-RAG) - Pints-AI ![Star](https://img.shields.io/github/stars/Pints-AI/Finetune-Bench-RAG.svg?style=social&label=Star) 

	 *Fine-tuning Models to Tackle Retrieval-Augmented Generation (RAG) Hallucination*
- [**chatwiki**](https://github.com/zhimaAi/chatwiki) - zhimaAi ![Star](https://img.shields.io/github/stars/zhimaAi/chatwiki.svg?style=social&label=Star) 
- [**graphiti**](https://github.com/getzep/graphiti) - getzep ![Star](https://img.shields.io/github/stars/getzep/graphiti.svg?style=social&label=Star) 
- [**RAG_Techniques**](https://github.com/NirDiamant/RAG_Techniques) - NirDiamant ![Star](https://img.shields.io/github/stars/NirDiamant/RAG_Techniques.svg?style=social&label=Star) 

	 *Elevating Your Retrieval-Augmented Generation Systems 🚀*
- [**LightRAG**](https://github.com/HKUDS/LightRAG) - HKUDS ![Star](https://img.shields.io/github/stars/HKUDS/LightRAG.svg?style=social&label=Star) 

	 *Simple and Fast Retrieval-Augmented Generation*
- [**pathway**](https://github.com/pathwaycom/pathway) - pathwaycom ![Star](https://img.shields.io/github/stars/pathwaycom/pathway.svg?style=social&label=Star) 
- [**onyx**](https://github.com/onyx-dot-app/onyx) - onyx-dot-app ![Star](https://img.shields.io/github/stars/onyx-dot-app/onyx.svg?style=social&label=Star) 
- [**fast-graphrag**](https://github.com/circlemind-ai/fast-graphrag) - circlemind-ai ![Star](https://img.shields.io/github/stars/circlemind-ai/fast-graphrag.svg?style=social&label=Star) 
- [**txtai**](https://github.com/neuml/txtai) - neuml ![Star](https://img.shields.io/github/stars/neuml/txtai.svg?style=social&label=Star) 
- [**Perplexica**](https://github.com/ItzCrazyKns/Perplexica) - ItzCrazyKns ![Star](https://img.shields.io/github/stars/ItzCrazyKns/Perplexica.svg?style=social&label=Star) 
- [**dsRAG**](https://github.com/D-Star-AI/dsRAG) - D-Star-AI ![Star](https://img.shields.io/github/stars/D-Star-AI/dsRAG.svg?style=social&label=Star) 
- 🌟 [**RAGViz**](https://github.com/cxcscmu/RAGViz) - cxcscmu ![Star](https://img.shields.io/github/stars/cxcscmu/RAGViz.svg?style=social&label=Star) 

	 · ([youtube](https://www.youtube.com/embed/cTAbuTu6ur4?si=-uZ2AyNLx-5p8MZC))
- [**pgai**](https://github.com/timescale/pgai) - timescale ![Star](https://img.shields.io/github/stars/timescale/pgai.svg?style=social&label=Star) 
- [Contextual RAG from Anthropic](https://x.com/togethercompute/status/1850939031301099919)  𝕏 

	 · ([together-cookbook](https://github.com/togethercomputer/together-cookbook/blob/main/Open_Contextual_RAG.ipynb) - togethercomputer) ![Star](https://img.shields.io/github/stars/togethercomputer/together-cookbook.svg?style=social&label=Star)
- [**AutoRAG**](https://github.com/Marker-Inc-Korea/AutoRAG) - Marker-Inc-Korea ![Star](https://img.shields.io/github/stars/Marker-Inc-Korea/AutoRAG.svg?style=social&label=Star) 
- [**KAG**](https://github.com/OpenSPG/KAG) - OpenSPG ![Star](https://img.shields.io/github/stars/OpenSPG/KAG.svg?style=social&label=Star) 

	 *Knowledge Augmented Generation*

## Products

- [Introducing Citations on the Anthropic API](https://www.anthropic.com/news/introducing-citations-api) 

## Misc

- [GraphRAG-esque metadata tagging + retrieval](https://x.com/jerryjliu0/status/1856768968973062620)  𝕏 

	 · ([llama_parse](https://github.com/run-llama/llama_parse/blob/main/examples/advanced_rag/dynamic_section_retrieval.ipynb) - run-llama) ![Star](https://img.shields.io/github/stars/run-llama/llama_parse.svg?style=social&label=Star)
- [What is Agentic RAG](https://weaviate.io/blog/what-is-agentic-rag) 

	 · ([𝕏](https://x.com/helloiamleonie/status/1853832634448687451))
- [Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge](https://huggingface.co/blog/digital-green-llm-judge)  🤗 

## Vector Database