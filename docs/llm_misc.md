# LLM Misc

- [LLM Misc](#llm-misc) 
  - [Survey](#survey)
  - [Interpretability](#interpretability)
  - [Unlearning](#unlearning)
  - [Personalization](#personalization)
  - [Forecasting](#forecasting)
  - [Detection](#detection)
  - [Generalization](#generalization)
  - [Editing](#editing)
  - [Calibration](#calibration)
  - [Tokenization](#tokenization)
  - [Visualization](#visualization)
  - [Privacy](#privacy)
  - [Society](#society)
  - [Tutorials](#tutorials)
  - [Toolkits](#toolkits)
  - [Misc Talks](#misc-talks)
  - [Misc](#misc)


## Survey

- 🌟 **A Survey of Context Engineering for Large Language Models**, `arXiv, 2507.13334`, [arxiv](http://arxiv.org/abs/2507.13334v2), [pdf](http://arxiv.org/pdf/2507.13334v2.pdf), cication: [**-1**](None) 

	 *Lingrui Mei, Jiayu Yao, Yuyao Ge, ..., Jiafeng Guo, Shenghua Liu*
- **Survey of different Large Language Model Architectures: Trends, 
  Benchmarks, and Challenges**, `ieee access, 2024`, [arxiv](http://arxiv.org/abs/2412.03220v1), [pdf](http://arxiv.org/pdf/2412.03220v1.pdf), cication: [**-1**](None) 

	 *Minghao Shao, Abdul Basit, Ramesh Karri, ..., Muhammad Shafique*
- **A Survey on Human-Centric LLMs**, `arXiv, 2411.14491`, [arxiv](http://arxiv.org/abs/2411.14491v2), [pdf](http://arxiv.org/pdf/2411.14491v2.pdf), cication: [**-1**](None) 

	 *Jing Yi Wang, Nicholas Sukiennik, Tong Li, ..., Fengli Xu, Yong Li*
- **Multilingual Large Language Models: A Systematic Survey**, `arXiv, 2411.11072`, [arxiv](http://arxiv.org/abs/2411.11072v2), [pdf](http://arxiv.org/pdf/2411.11072v2.pdf), cication: [**-1**](None) 

	 *Shaolin Zhu, Supryadi, Shaoyang Xu, ..., António Branco, Deyi Xiong* · ([Awesome-Multilingual-LLMs-Papers](https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers) - tjunlp-lab) ![Star](https://img.shields.io/github/stars/tjunlp-lab/Awesome-Multilingual-LLMs-Papers.svg?style=social&label=Star)
- [**awesome-discrete-diffusion-models**](https://github.com/kuleshov-group/awesome-discrete-diffusion-models) - kuleshov-group ![Star](https://img.shields.io/github/stars/kuleshov-group/awesome-discrete-diffusion-models.svg?style=social&label=Star) 
- **Survey of Cultural Awareness in Language Models: Text and Beyond**, `arXiv, 2411.00860`, [arxiv](http://arxiv.org/abs/2411.00860v1), [pdf](http://arxiv.org/pdf/2411.00860v1.pdf), cication: [**-1**](None) 

	 *Siddhesh Pawar, Junyeong Park, Jiho Jin, ..., Alice Oh, Isabelle Augenstein*
- **LLM-based Optimization of Compound AI Systems: A Survey**, `arXiv, 2410.16392`, [arxiv](http://arxiv.org/abs/2410.16392v1), [pdf](http://arxiv.org/pdf/2410.16392v1.pdf), cication: [**-1**](None) 

	 *Matthieu Lin, Jenny Sheng, Andrew Zhao, ..., Gao Huang, Yong-Jin Liu*

	 · ([LLM-based-Optimization-of-Compound-AI-Systems](https://github.com/linyuhongg/LLM-based-Optimization-of-Compound-AI-Systems) - linyuhongg) ![Star](https://img.shields.io/github/stars/linyuhongg/LLM-based-Optimization-of-Compound-AI-Systems.svg?style=social&label=Star)
- **Ecosystem Graphs: The Social Footprint of Foundation Models**, `arXiv, 2303.15772`, [arxiv](http://arxiv.org/abs/2303.15772v1), [pdf](http://arxiv.org/pdf/2303.15772v1.pdf), cication: [**26**](https://scholar.google.com/scholar?cites=1512209463489040407&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Rishi Bommasani, Dilara Soylu, Thomas I. Liao, ..., Kathleen A. Creel, Percy Liang* · ([crfm.stanford](https://crfm.stanford.edu/ecosystem-graphs/))

## Interpretability

- 🌟 **Does Math Reasoning Improve General LLM Capabilities? Understanding
  Transferability of LLM Reasoning**, `arXiv, 2507.00432`, [arxiv](http://arxiv.org/abs/2507.00432v1), [pdf](http://arxiv.org/pdf/2507.00432v1.pdf), cication: [**-1**](None) 

	 *Maggie Huan, Yuetai Li, Tuney Zheng, ..., Graham Neubig, Xiang Yue*
- **The Invisible Leash: Why RLVR May Not Escape Its Origin**, `arXiv, 2507.14843`, [arxiv](http://arxiv.org/abs/2507.14843v1), [pdf](http://arxiv.org/pdf/2507.14843v1.pdf), cication: [**-1**](None) 

	 *Fang Wu, Weihao Xuan, Ximing Lu, ..., Zaid Harchaoui, Yejin Choi*
- **Thought Anchors: Which LLM Reasoning Steps Matter?**, `arXiv, 2506.19143`, [arxiv](http://arxiv.org/abs/2506.19143v2), [pdf](http://arxiv.org/pdf/2506.19143v2.pdf), cication: [**-1**](None) 

	 *Paul C. Bogdan, Uzay Macar, Neel Nanda, ..., Arthur Conmy*
- **How much do language models memorize?**, `arXiv, 2505.24832`, [arxiv](http://arxiv.org/abs/2505.24832v2), [pdf](http://arxiv.org/pdf/2505.24832v2.pdf), cication: [**-1**](None) 

	 *John X. Morris, Chawin Sitawarin, Chuan Guo, ..., Kamalika Chaudhuri, Saeed Mahloujifar*
- [**circuit-tracer**](https://github.com/safety-research/circuit-tracer) - safety-research ![Star](https://img.shields.io/github/stars/safety-research/circuit-tracer.svg?style=social&label=Star) 
- **Beyond Semantics: The Unreasonable Effectiveness of Reasonless 
  Intermediate Tokens**, `arXiv, 2505.13775`, [arxiv](http://arxiv.org/abs/2505.13775v1), [pdf](http://arxiv.org/pdf/2505.13775v1.pdf), cication: [**-1**](None) 

	 *Kaya Stechly, Karthik Valmeekam, Atharva Gundawar, ..., Vardhan Palod, Subbarao Kambhampati*
- **Reinforcement Learning Finetunes Small Subnetworks in Large Language 
  Models**, `arXiv, 2505.11711`, [arxiv](http://arxiv.org/abs/2505.11711v1), [pdf](http://arxiv.org/pdf/2505.11711v1.pdf), cication: [**-1**](None) 

	 *Sagnik Mukherjee, Lifan Yuan, Dilek Hakkani-Tur, ..., Hao Peng*
- **Massive Values in Self-Attention Modules are the Key to Contextual 
  Knowledge Understanding**, `arXiv, 2502.01563`, [arxiv](http://arxiv.org/abs/2502.01563v4), [pdf](http://arxiv.org/pdf/2502.01563v4.pdf), cication: [**-1**](None) 

	 *Mingyu Jin, Kai Mei, Wujiang Xu, ..., Zirui Liu, Yongfeng Zhang*
- **Inside-Out: Hidden Factual Knowledge in LLMs**, `arXiv, 2503.15299`, [arxiv](http://arxiv.org/abs/2503.15299v2), [pdf](http://arxiv.org/pdf/2503.15299v2.pdf), cication: [**-1**](None) 

	 *Zorik Gekhman, Eyal Ben David, Hadas Orgad, ..., Jonathan Herzig, Roi Reichart*
- **I Have Covered All the Bases Here: Interpreting Reasoning Features in 
  Large Language Models via Sparse Autoencoders**, `arXiv, 2503.18878`, [arxiv](http://arxiv.org/abs/2503.18878v1), [pdf](http://arxiv.org/pdf/2503.18878v1.pdf), cication: [**-1**](None) 

	 *Andrey Galichin, Alexey Dontsov, Polina Druzhinina, ..., Elena Tutubalina, Ivan Oseledets* · ([SAE-Reasoning](https://github.com/AIRI-Institute/SAE-Reasoning) - AIRI-Institute) ![Star](https://img.shields.io/github/stars/AIRI-Institute/SAE-Reasoning.svg?style=social&label=Star)
- **Landscape of Thoughts: Visualizing the Reasoning Process of Large 
  Language Models**, `arXiv, 2503.22165`, [arxiv](http://arxiv.org/abs/2503.22165v1), [pdf](http://arxiv.org/pdf/2503.22165v1.pdf), cication: [**-1**](None) 

	 *Zhanke Zhou, Zhaocheng Zhu, Xuan Li, ..., Jian Tang, Bo Han* · ([landscape-of-thoughts.](https://github.com/tmlr-group/landscape-of-thoughts.) - tmlr-group) ![Star](https://img.shields.io/github/stars/tmlr-group/landscape-of-thoughts..svg?style=social&label=Star)
- **OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training 
  Tokens**, `arXiv, 2504.07096`, [arxiv](http://arxiv.org/abs/2504.07096v1), [pdf](http://arxiv.org/pdf/2504.07096v1.pdf), cication: [**-1**](None) 

	 *Jiacheng Liu, Taylor Blanton, Yanai Elazar, ..., Ali Farhadi, Jesse Dodge*
- **Mixture of Experts Made Intrinsically Interpretable**, `arXiv, 2503.07639`, [arxiv](http://arxiv.org/abs/2503.07639v1), [pdf](http://arxiv.org/pdf/2503.07639v1.pdf), cication: [**-1**](None) 

	 *Xingyi Yang, Constantin Venhoff, Ashkan Khakzar, ..., Adel Bibi, Philip Torr*
- [Can lossless information compression by itself produce intelligent behavior?](https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html) 
- **Are Sparse Autoencoders Useful? A Case Study in Sparse Probing**, `arXiv, 2502.16681`, [arxiv](http://arxiv.org/abs/2502.16681v1), [pdf](http://arxiv.org/pdf/2502.16681v1.pdf), cication: [**-1**](None) 

	 *Subhash Kantamneni, Joshua Engels, Senthooran Rajamanoharan, ..., Max Tegmark, Neel Nanda* · ([𝕏](https://x.com/JoshAEngels/status/1894385838487642346)) · ([SAE-Probes](https://github.com/JoshEngels/SAE-Probes) - JoshEngels) ![Star](https://img.shields.io/github/stars/JoshEngels/SAE-Probes.svg?style=social&label=Star)
- 🌟 **LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context 
  Memory of Transformers**, `arXiv, 2502.15007`, [arxiv](http://arxiv.org/abs/2502.15007v1), [pdf](http://arxiv.org/pdf/2502.15007v1.pdf), cication: [**-1**](None) 

	 *Anton Razzhigaev, Matvey Mikhalchuk, Temurbek Rahmatullaev, ..., Ivan Oseledets, Andrey Kuznetsov*
- **How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on 
  Continual Pre-Training**, `arXiv, 2502.11196`, [arxiv](http://arxiv.org/abs/2502.11196v1), [pdf](http://arxiv.org/pdf/2502.11196v1.pdf), cication: [**-1**](None) 

	 *Yixin Ou, Yunzhi Yao, Ningyu Zhang, ..., Zhenguo Li, Huajun Chen*
- **Open Problems in Mechanistic Interpretability**, `arXiv, 2501.16496`, [arxiv](http://arxiv.org/abs/2501.16496v1), [pdf](http://arxiv.org/pdf/2501.16496v1.pdf), cication: [**-1**](None) 

	 *Lee Sharkey, Bilal Chughtai, Joshua Batson, ..., Daniel Murfet, Tom McGrath*
- 🌟 **Analyze Feature Flow to Enhance Interpretation and Steering in Language 
  Models**, `arXiv, 2502.03032`, [arxiv](http://arxiv.org/abs/2502.03032v2), [pdf](http://arxiv.org/pdf/2502.03032v2.pdf), cication: [**-1**](None) 

	 *Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, ..., Daniil Gavrilov*
- [Announcing Open-Source SAEs for Llama 3.3 70B and Llama 3.1 8B](https://www.goodfire.ai/blog/sae-open-source-announcement/) 

	 · ([𝕏](https://x.com/GoodfireAI/status/1877777694936694962))
- [The Dark Matter of AI [Mechanistic Interpretability]](https://www.youtube.com/watch?v=UGO_Ehywuxc)  :clapper: 
- [Goodfire Ember: Scaling Interpretability for Frontier Model Alignment](https://www.goodfire.ai/blog/announcing-goodfire-ember/) 

	 · ([𝕏](https://x.com/GoodfireAI/status/1871241896942612518))
- [Understanding Transformer reasoning capabilities via graph algorithms](https://research.google/blog/understanding-transformer-reasoning-capabilities-via-graph-algorithms/) 
- **Towards scientific discovery with dictionary learning: Extracting 
  biological concepts from microscopy foundation models**, `arXiv, 2412.16247`, [arxiv](http://arxiv.org/abs/2412.16247v1), [pdf](http://arxiv.org/pdf/2412.16247v1.pdf), cication: [**-1**](None) 

	 *Konstantin Donhauser, Kristina Ulicna, Gemma Elyse Moran, ..., Cian Eastwood, Jason Hartford*
- **Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language 
  Models**, `arXiv, 2412.06748`, [arxiv](http://arxiv.org/abs/2412.06748v1), [pdf](http://arxiv.org/pdf/2412.06748v1.pdf), cication: [**-1**](None) 

	 *Neel Jain, Aditya Shrivastava, Chenyang Zhu, ..., Micah Goldblum, Tom Goldstein*
- **Emergence of Abstractions: Concept Encoding and Decoding Mechanism for 
  In-Context Learning in Transformers**, `arXiv, 2412.12276`, [arxiv](http://arxiv.org/abs/2412.12276v2), [pdf](http://arxiv.org/pdf/2412.12276v2.pdf), cication: [**-1**](None) 

	 *Seungwook Han, Jinyeop Song, Jeff Gore, ..., Pulkit Agrawal*
- **Frame Representation Hypothesis: Multi-Token LLM Interpretability and 
  Concept-Guided Text Generation**, `arXiv, 2412.07334`, [arxiv](http://arxiv.org/abs/2412.07334v2), [pdf](http://arxiv.org/pdf/2412.07334v2.pdf), cication: [**-1**](None) 

	 *Pedro H. V. Valois, Lincon S. Souza, Erica K. Shimomoto, ..., Kazuhiro Fukui* · ([frame-representation-hypothesis.git](https://github.com/phvv-me/frame-representation-hypothesis.git) - phvv-me) ![Star](https://img.shields.io/github/stars/phvv-me/frame-representation-hypothesis.git.svg?style=social&label=Star)
- 🌟 **Critical Tokens Matter: Token-Level Contrastive Estimation Enhances 
  LLM's Reasoning Capability**, `arXiv, 2411.19943`, [arxiv](http://arxiv.org/abs/2411.19943v2), [pdf](http://arxiv.org/pdf/2411.19943v2.pdf), cication: [**-1**](None) 

	 *Zicheng Lin, Tian Liang, Jiahao Xu, ..., Yujiu Yang, Zhaopeng Tu*
- **Large Multi-modal Models Can Interpret Features in Large Multi-modal 
  Models**, `arXiv, 2411.14982`, [arxiv](http://arxiv.org/abs/2411.14982v1), [pdf](http://arxiv.org/pdf/2411.14982v1.pdf), cication: [**-1**](None) 

	 *Kaichen Zhang, Yifei Shen, Bo Li, ..., Ziwei Liu*
- **LLMs Do Not Think Step-by-step In Implicit Reasoning**, `arXiv, 2411.15862`, [arxiv](http://arxiv.org/abs/2411.15862v1), [pdf](http://arxiv.org/pdf/2411.15862v1.pdf), cication: [**-1**](None) 

	 *Yijiong Yu*

	 · ([𝕏](https://x.com/TheAITimeline/status/1863350188019949808))
- **Large Multi-modal Models Can Interpret Features in Large Multi-modal 
  Models**, `arXiv, 2411.14982`, [arxiv](http://arxiv.org/abs/2411.14982v1), [pdf](http://arxiv.org/pdf/2411.14982v1.pdf), cication: [**-1**](None) 

	 *Kaichen Zhang, Yifei Shen, Bo Li, ..., Ziwei Liu* · ([multimodal-sae](https://github.com/EvolvingLMMs-Lab/multimodal-sae) - EvolvingLMMs-Lab) ![Star](https://img.shields.io/github/stars/EvolvingLMMs-Lab/multimodal-sae.svg?style=social&label=Star)
- **Do Large Language Models Perform Latent Multi-Hop Reasoning without 
  Exploiting Shortcuts?**, `arXiv, 2411.16679`, [arxiv](http://arxiv.org/abs/2411.16679v1), [pdf](http://arxiv.org/pdf/2411.16679v1.pdf), cication: [**-1**](None) 

	 *Sohee Yang, Nora Kassner, Elena Gribovskaya, ..., Sebastian Riedel, Mor Geva* · ([𝕏](https://x.com/soheeyang_/status/1861822094289367415))
- **Procedural Knowledge in Pretraining Drives Reasoning in Large Language 
  Models**, `arXiv, 2411.12580`, [arxiv](http://arxiv.org/abs/2411.12580v1), [pdf](http://arxiv.org/pdf/2411.12580v1.pdf), cication: [**-1**](None) 

	 *Laura Ruis, Maximilian Mozes, Juhan Bae, ..., Edward Grefenstette, Max Bartolo*
- [Dario Amodei: Anthropic CEO on Claude, AGI & the Future of AI & Humanity | Lex Fridman Podcast #452](https://www.youtube.com/)  :clapper: 
- [The Rate Distortion Dance of Sparse Autoencoders](https://tilderesearch.com/blog) 

	 · ([𝕏](https://x.com/tilderesearch/status/1856404543808131334))
- **The Semantic Hub Hypothesis: Language Models Share Semantic 
  Representations Across Languages and Modalities**, `arXiv, 2411.04986`, [arxiv](http://arxiv.org/abs/2411.04986v1), [pdf](http://arxiv.org/pdf/2411.04986v1.pdf), cication: [**-1**](None) 

	 *Zhaofeng Wu, Xinyan Velocity Yu, Dani Yogatama, ..., Jiasen Lu, Yoon Kim*
- **Interpretable Language Modeling via Induction-head Ngram Models**, `arXiv, 2411.00066`, [arxiv](http://arxiv.org/abs/2411.00066v1), [pdf](http://arxiv.org/pdf/2411.00066v1.pdf), cication: [**-1**](None) 

	 *Eunji Kim, Sriya Mantena, Weiwei Yang, ..., Sungroh Yoon, Jianfeng Gao* · ([induction-gram](https://github.com/ejkim47/induction-gram?tab=readme-ov-file) - ejkim47) ![Star](https://img.shields.io/github/stars/ejkim47/induction-gram.svg?style=social&label=Star)
- **Analyzing The Language of Visual Tokens**, `arXiv, 2411.05001`, [arxiv](http://arxiv.org/abs/2411.05001v1), [pdf](http://arxiv.org/pdf/2411.05001v1.pdf), cication: [**-1**](None) 

	 *David M. Chan, Rodolfo Corona, Joonyong Park, ..., Yutong Bai, Trevor Darrell*
- **Physics in Next-token Prediction**, `arXiv, 2411.00660`, [arxiv](http://arxiv.org/abs/2411.00660v1), [pdf](http://arxiv.org/pdf/2411.00660v1.pdf), cication: [**-1**](None) 

	 *Hongjun An, Yiliang Song, Xuelong Li* · ([youtube](https://www.youtube.com/watch?v=hzQLqVZKn7c))
- **Mixture of Parrots: Experts improve memorization more than reasoning**, `arXiv, 2410.19034`, [arxiv](http://arxiv.org/abs/2410.19034v1), [pdf](http://arxiv.org/pdf/2410.19034v1.pdf), cication: [**-1**](None) 

	 *Samy Jelassi, Clara Mohri, David Brandfonbrener, ..., Sham M. Kakade, Eran Malach*
- **On Memorization of Large Language Models in Logical Reasoning**, `arXiv, 2410.23123`, [arxiv](http://arxiv.org/abs/2410.23123v1), [pdf](http://arxiv.org/pdf/2410.23123v1.pdf), cication: [**-1**](None) 

	 *Chulin Xie, Yangsibo Huang, Chiyuan Zhang, ..., Badih Ghazi, Ravi Kumar* · ([mem-kk-logic](https://github.com/AlphaPav/mem-kk-logic/) - AlphaPav) ![Star](https://img.shields.io/github/stars/AlphaPav/mem-kk-logic.svg?style=social&label=Star) · ([memkklogic.github](https://memkklogic.github.io/))
- **What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A 
  Gradient Perspective**, `arXiv, 2410.23743`, [arxiv](http://arxiv.org/abs/2410.23743v1), [pdf](http://arxiv.org/pdf/2410.23743v1.pdf), cication: [**-1**](None)

	 *Ming Li, Yanhong Li, Tianyi Zhou* · ([Layer_Gradient](https://github.com/MingLiiii/Layer_Gradient) - MingLiiii) ![Star](https://img.shields.io/github/stars/MingLiiii/Layer_Gradient.svg?style=social&label=Star) · ([aimodels](https://www.aimodels.fyi/papers/arxiv/what-happened-llms-layers-when-trained-fast))
- **Arithmetic Without Algorithms: Language Models Solve Math With a Bag of 
  Heuristics**, `arXiv, 2410.21272`, [arxiv](http://arxiv.org/abs/2410.21272v1), [pdf](http://arxiv.org/pdf/2410.21272v1.pdf), cication: [**-1**](None)

	 *Yaniv Nikankin, Anja Reusch, Aaron Mueller, ..., Yonatan Belinkov* · ([x](https://x.com/omarsar0/status/1851233281116946923))
- **Large Language Models Reflect the Ideology of their Creators**, `arXiv, 2410.18417`, [arxiv](http://arxiv.org/abs/2410.18417v1), [pdf](http://arxiv.org/pdf/2410.18417v1.pdf), cication: [**-1**](None) 

	 *Maarten Buyl, Alexander Rogiers, Sander Noels, ..., Jefrey Lijffijt, Tijl De Bie*
- [Evaluating feature steering: A case study in mitigating social biases](https://www.anthropic.com/research/evaluating-feature-steering) 

	 · ([x](https://x.com/AnthropicAI/status/1849840131412296039))
- [Introducing Transluce](https://transluce.org/introducing-transluce) 
- :clapper: [ICML 2024 Tutorial: Physics of Language Models](https://www.youtube.com/watch?v=yBL7J0kgldU) 
- [Physics of Language Models](https://physics.allen-zhu.com/home) 

	 · ([bilibili](https://www.bilibili.com/video/BV1Yw4m1k7nH/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=63e5fa02f07bfd58e74de3c6d149e31f))

## Unlearning

- **ReLearn: Unlearning via Learning for Large Language Models**, `arXiv, 2502.11190`, [arxiv](http://arxiv.org/abs/2502.11190v1), [pdf](http://arxiv.org/pdf/2502.11190v1.pdf), cication: [**-1**](None) 

	 *Haoming Xu, Ningyuan Zhao, Liming Yang, ..., Huajun Chen, Ningyu Zhang* · ([unlearn](https://github.com/zjunlp/unlearn) - zjunlp) ![Star](https://img.shields.io/github/stars/zjunlp/unlearn.svg?style=social&label=Star)
- **Does your LLM truly unlearn? An embarrassingly simple approach to 
  recover unlearned knowledge**, `arXiv, 2410.16454`, [arxiv](http://arxiv.org/abs/2410.16454v1), [pdf](http://arxiv.org/pdf/2410.16454v1.pdf), cication: [**-1**](None) 

	 *Zhiwei Zhang, Fali Wang, Xiaomin Li, ..., Wenpeng Yin, Suhang Wang* · ([𝕏](https://x.com/llm_sec/status/1853533265774436816)) · ([t](https://t.co/Gn3AOAn48D))
- 🌟 **CLEAR: Character Unlearning in Textual and Visual Modalities**, `arXiv, 2410.18057`, [arxiv](http://arxiv.org/abs/2410.18057v1), [pdf](http://arxiv.org/pdf/2410.18057v1.pdf), cication: [**-1**](None) 

	 *Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, ..., Ivan Oseledets, Elena Tutubalina* · ([huggingface](https://huggingface.co/datasets/therem/CLEAR)) · ([multimodal_unlearning](https://github.com/somvy/multimodal_unlearning) - somvy) ![Star](https://img.shields.io/github/stars/somvy/multimodal_unlearning.svg?style=social&label=Star)

## Personalization

- **Personalization of Large Language Models: A Survey**, `arXiv, 2411.00027`, [arxiv](http://arxiv.org/abs/2411.00027v1), [pdf](http://arxiv.org/pdf/2411.00027v1.pdf), cication: [**-1**](None) 

	 *Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, ..., Nesreen Ahmed, Yu Wang*

## Forecasting


## Detection

- 🌟 **Feature-Level Insights into Artificial Text Detection with Sparse 
  Autoencoders**, `arXiv, 2503.03601`, [arxiv](http://arxiv.org/abs/2503.03601v1), [pdf](http://arxiv.org/pdf/2503.03601v1.pdf), cication: [**-1**](None) 

	 *Kristian Kuznetsov, Laida Kushnareva, Polina Druzhinina, ..., Evgeny Burnaev, Serguei Barannikov*
- **LLMmap: Fingerprinting For Large Language Models**, `arXiv, 2407.15847`, [arxiv](http://arxiv.org/abs/2407.15847v3), [pdf](http://arxiv.org/pdf/2407.15847v3.pdf), cication: [**-1**](None) 

	 *Dario Pasquini, Evgenios M. Kornaropoulos, Giuseppe Ateniese*
- **Robust Watermarking Using Generative Priors Against Image Editing: From 
  Benchmarking to Advances**, `arXiv, 2410.18775`, [arxiv](http://arxiv.org/abs/2410.18775v1), [pdf](http://arxiv.org/pdf/2410.18775v1.pdf), cication: [**-1**](None)

	 *Shilin Lu, Zihan Zhou, Jiayou Lu, ..., Yuanzhi Zhu, Adams Wai-Kin Kong*

	 · ([VINE](https://github.com/Shilin-LU/VINE) - Shilin-LU) ![Star](https://img.shields.io/github/stars/Shilin-LU/VINE.svg?style=social&label=Star)
- [Introducing SynthID Text](https://huggingface.co/blog/synthid-text)  🤗 
- **A Watermark for Black-Box Language Models**, `arXiv, 2410.02099`, [arxiv](http://arxiv.org/abs/2410.02099v1), [pdf](http://arxiv.org/pdf/2410.02099v1.pdf), cication: [**-1**](None) 

	 *Dara Bahri, John Wieting, Dana Alon, ..., Donald Metzler*
- **Are AI Detectors Good Enough? A Survey on Quality of Datasets With 
  Machine-Generated Texts**, `arXiv, 2410.14677`, [arxiv](http://arxiv.org/abs/2410.14677v1), [pdf](http://arxiv.org/pdf/2410.14677v1.pdf), cication: [**-1**](None)

	 *German Gritsai, Anastasia Voznyuk, Andrey Grabovoy, ..., Yury Chekhovich*

## Generalization


## Editing

- **EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language 
  Models**, `arXiv, 2504.15133`, [arxiv](http://arxiv.org/abs/2504.15133v1), [pdf](http://arxiv.org/pdf/2504.15133v1.pdf), cication: [**-1**](None) 

	 *Ziwen Xu, Shuxun Wang, Kewei Xu, ..., Huajun Chen, Ningyu Zhang* · ([zjunlp.github](https://zjunlp.github.io/project/EasyEdit2/video))
- [uncensored version of Qwen/QwQ-32B-Preview created with abliteration](https://huggingface.co/huihui-ai/QwQ-32B-Preview-abliterated)  🤗 

	 · ([remove-refusals-with-transformers](https://github.com/Sumandora/remove-refusals-with-transformers) - Sumandora) ![Star](https://img.shields.io/github/stars/Sumandora/remove-refusals-with-transformers.svg?style=social&label=Star)
- **Can Knowledge Editing Really Correct Hallucinations?**, `arXiv, 2410.16251`, [arxiv](http://arxiv.org/abs/2410.16251v2), [pdf](http://arxiv.org/pdf/2410.16251v2.pdf), cication: [**-1**](None) 

	 *Baixiang Huang, Canyu Chen, Xiongxiao Xu, ..., Ali Payani, Kai Shu*

	 · ([llm-editing.github](https://llm-editing.github.io/))

## Calibration


## Tokenization

- [Whole words and Claude tokenization](https://tokencontributions.substack.com/p/whole-words-and-claude-tokenization) 
- 🌟 **Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the 
  Limits of Embedding Space Capacity**, `arXiv, 2502.13063`, [arxiv](http://arxiv.org/abs/2502.13063v1), [pdf](http://arxiv.org/pdf/2502.13063v1.pdf), cication: [**-1**](None) 

	 *Yuri Kuratov, Mikhail Arkhipov, Aydar Bulatov, ..., Mikhail Burtsev*
- **Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling**, `arXiv, 2501.16975`, [arxiv](http://arxiv.org/abs/2501.16975v1), [pdf](http://arxiv.org/pdf/2501.16975v1.pdf), cication: [**-1**](None) 

	 *Hongzhi Huang, Defa Zhu, Banggu Wu, ..., Qiyang Min, Xun Zhou*
- [Byte Latent Transformer: Patches Scale Better Than Tokens](https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/) 
- [added a few lines of code to the base Llama 3 tokenizer and got a free boost in arithmetic performance](https://x.com/garrethleee/status/1860039446311371132)  𝕏 
- **Counting Ability of Large Language Models and Impact of Tokenization**, `arXiv, 2410.19730`, [arxiv](http://arxiv.org/abs/2410.19730v2), [pdf](http://arxiv.org/pdf/2410.19730v2.pdf), cication: [**-1**](None) 

	 *Xiang Zhang, Juntai Cao, Chenyu You*

## Visualization

- [**data-formulator**](https://github.com/microsoft/data-formulator) - microsoft ![Star](https://img.shields.io/github/stars/microsoft/data-formulator.svg?style=social&label=Star) 

	 *Create Rich Visualizations with AI*

## Privacy

- **PAPILLON: PrivAcy Preservation from Internet-based and Local Language 
  MOdel ENsembles**, `arXiv, 2410.17127`, [arxiv](http://arxiv.org/abs/2410.17127v1), [pdf](http://arxiv.org/pdf/2410.17127v1.pdf), cication: [**-1**](None)

	 *Li Siyan, Vethavikashini Chithrra Raghuram, Omar Khattab, ..., Julia Hirschberg, Zhou Yu* · ([PAPILLON](https://github.com/siyan-sylvia-li/PAPILLON) - siyan-sylvia-li) ![Star](https://img.shields.io/github/stars/siyan-sylvia-li/PAPILLON.svg?style=social&label=Star)

## Society


## Tutorials

- [How Transformer LLMs Work](https://www.deeplearning.ai/short-courses/how-transformer-llms-work/?utm_campaign=handsonllm-launch&utm_medium=partner) 
- [**smol-course**](https://github.com/huggingface/smol-course) - huggingface ![Star](https://img.shields.io/github/stars/huggingface/smol-course.svg?style=social&label=Star) 
- [Understanding LLMs from Scratch Using Middle School Math](https://towardsdatascience.com/understanding-llms-from-scratch-using-middle-school-math-e602d27ec876) 
- [An attempt to reconstruct Ilya Sutskever's 2020 AI reading list](https://tensorlabbet.com/2024/11/11/lost-reading-items/) 

## Toolkits


## Misc Talks


## Misc

- **Apple Intelligence Foundation Language Models: Tech Report 2025**, `arXiv, 2507.13575`, [arxiv](http://arxiv.org/abs/2507.13575v1), [pdf](http://arxiv.org/pdf/2507.13575v1.pdf), cication: [**-1**](None) 

	 *Hanzhi Zhou, Erik Hornberger, Pengsheng Guo, ..., Xiujun Li, Shang-Chen Wu*
- [NUS120 Distinguished Speaker Series | Professor Richard Sutton](https://www.youtube.com/watch?v=f9KDMFZqu_Y)  :clapper: 

	 · ([youtu](https://youtu.be/f9KDMFZqu_Y?t=797))
- [**Foundations-of-LLMs**](https://github.com/ZJU-LLMs/Foundations-of-LLMs) - ZJU-LLMs ![Star](https://img.shields.io/github/stars/ZJU-LLMs/Foundations-of-LLMs.svg?style=social&label=Star) 
- [【生成式AI時代下的機器學習(2025)】第一講：一堂課搞懂生成式人工智慧的技術突破與未來發展](https://www.youtube.com/watch?v=QLiKmca4kzI)  :clapper: 
- [How I use LLMs](https://www.youtube.com/watch?v=EWvNQjAaOHw)  :clapper: 
- **Idiosyncrasies in Large Language Models**, `arXiv, 2502.12150`, [arxiv](http://arxiv.org/abs/2502.12150v1), [pdf](http://arxiv.org/pdf/2502.12150v1.pdf), cication: [**-1**](None) 

	 *Mingjie Sun, Yida Yin, Zhiqiu Xu, ..., J. Zico Kolter, Zhuang Liu* · ([eric-mingjie.github](https://eric-mingjie.github.io/llm-idiosyncrasies/)) · ([𝕏](https://x.com/liuzhuang1234/status/1892430119395873015))
- [Jeff Dean & Noam Shazeer – 25 years at Google: from PageRank to AGI](https://www.youtube.com/watch?v=v0gjI__RyCY)  :clapper: 
- [Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs](https://openreview.net/forum?id=FBkpCyujtS) 
- 🌟 [Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI)  :clapper: 
- **Model Equality Testing: Which Model Is This API Serving?**, `arXiv, 2410.20247`, [arxiv](http://arxiv.org/abs/2410.20247v1), [pdf](http://arxiv.org/pdf/2410.20247v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=3413611661521382563&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Irena Gao, Percy Liang, Carlos Guestrin* · ([𝕏](https://x.com/irena_gao/status/1851273717504159911))
- **Can LLMs Design Good Questions Based on Context?**, `arXiv, 2501.03491`, [arxiv](http://arxiv.org/abs/2501.03491v1), [pdf](http://arxiv.org/pdf/2501.03491v1.pdf), cication: [**-1**](None) 

	 *Yueheng Zhang, Xiaoyuan Liu, Yiyou Sun, ..., Basel Alomair, Dawn Song*
- [**awesome-generative-ai**](https://github.com/steven2358/awesome-generative-ai) - steven2358 ![Star](https://img.shields.io/github/stars/steven2358/awesome-generative-ai.svg?style=social&label=Star) 
- [Advanced Natural Language Processing](https://cmu-l3.github.io/anlp-spring2025/) 
- [Speech and Language Processing(3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/) 
- [CIS 7000 - Large Language Models](https://llm-class.github.io/) 
- [WHAT LLM PROVIDER?](https://whatllm.vercel.app/) 