# LLM Long Context

- [LLM Long Context](#llm-long-context) 
  - [Survey](#survey)
  - [Long Context](#long-context)
  - [Evaluation](#evaluation)
  - [Projects](#projects)
  - [Misc](#misc)


## Survey

- **A Comprehensive Survey on Long Context Language Modeling**, `arXiv, 2503.17407`, [arxiv](http://arxiv.org/abs/2503.17407v1), [pdf](http://arxiv.org/pdf/2503.17407v1.pdf), cication: [**-1**](None) 

	 *Jiaheng Liu, Dawei Zhu, Zhiqi Bai, ..., Sujian Li, Zhaoxiang Zhang* 路 ([A-Comprehensive-Survey-For-Long-Context-Language-Modeling](https://github.com/LCLM-Horizon/A-Comprehensive-Survey-For-Long-Context-Language-Modeling) - LCLM-Horizon) ![Star](https://img.shields.io/github/stars/LCLM-Horizon/A-Comprehensive-Survey-For-Long-Context-Language-Modeling.svg?style=social&label=Star)

## Long Context

- **LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement
  Learning**, `arXiv, 2506.18841`, [arxiv](http://arxiv.org/abs/2506.18841v1), [pdf](http://arxiv.org/pdf/2506.18841v1.pdf), cication: [**-1**](None) 

	 *Yuhao Wu, Yushi Bai, Zhiqiang Hu, ..., Roy Ka-Wei Lee, Juanzi Li* 路 ([huggingface](https://huggingface.co/THU-KEG/LongWriter-Zero-32B))
-  **Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning**, `arXiv, 2507.16784`, [arxiv](http://arxiv.org/abs/2507.16784v1), [pdf](http://arxiv.org/pdf/2507.16784v1.pdf), cication: [**-1**](None) 

	 *Hongyin Luo, Nathaniel Morgan, Tina Li, ..., Jack O'Brien, James Glass*
- **Understanding and Improving Length Generalization in Recurrent Models**, `arXiv, 2507.02782`, [arxiv](http://arxiv.org/abs/2507.02782v1), [pdf](http://arxiv.org/pdf/2507.02782v1.pdf), cication: [**-1**](None) 

	 *Ricardo Buitrago Ruiz, Albert Gu*
- **LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs**, `arXiv, 2506.14429`, [arxiv](http://arxiv.org/abs/2506.14429v1), [pdf](http://arxiv.org/pdf/2506.14429v1.pdf), cication: [**-1**](None) 

	 *Xiaoran Liu, Zhigeng Liu, Zengfeng Huang, ..., Ziwei He, Xipeng Qiu*
- **QwenLong-L1: Towards Long-Context Large Reasoning Models with 
  Reinforcement Learning**, `arXiv, 2505.17667`, [arxiv](http://arxiv.org/abs/2505.17667v2), [pdf](http://arxiv.org/pdf/2505.17667v2.pdf), cication: [**-1**](None) 

	 *Fanqi Wan, Weizhou Shen, Shengyi Liao, ..., Jingren Zhou, Ming Yan* 路 ([QwenLong-L1](https://github.com/Tongyi-Zhiwen/QwenLong-L1) - Tongyi-Zhiwen) ![Star](https://img.shields.io/github/stars/Tongyi-Zhiwen/QwenLong-L1.svg?style=social&label=Star) 路 ([huggingface](https://huggingface.co/Tongyi-Zhiwen/QwenLong-L1-32B)) 路 ([modelscope](https://modelscope.cn/models/iic/QwenLong-L1-32B))
- **QwenLong-CPRS: Towards $\infty$-LLMs with Dynamic Context Optimization**, `arXiv, 2505.18092`, [arxiv](http://arxiv.org/abs/2505.18092v2), [pdf](http://arxiv.org/pdf/2505.18092v2.pdf), cication: [**-1**](None) 

	 *Weizhou Shen, Chenliang Li, Fanqi Wan, ..., Jingren Zhou, Ming Yan*
- **RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM 
  Inference**, `arXiv, 2505.02922`, [arxiv](http://arxiv.org/abs/2505.02922v1), [pdf](http://arxiv.org/pdf/2505.02922v1.pdf), cication: [**-1**](None) 

	 *Yaoqi Chen, Jinkai Zhang, Baotong Lu, ..., Fan Yang, Mao Yang* 路 ([RetrievalAttention](https://github.com/microsoft/RetrievalAttention) - microsoft) ![Star](https://img.shields.io/github/stars/microsoft/RetrievalAttention.svg?style=social&label=Star)
- **From 128K to 4M: Efficient Training of Ultra-Long Context Large Language 
  Models**, `arXiv, 2504.06214`, [arxiv](http://arxiv.org/abs/2504.06214v1), [pdf](http://arxiv.org/pdf/2504.06214v1.pdf), cication: [**-1**](None) 

	 *Chejian Xu, Wei Ping, Peng Xu, ..., Bo Li, Bryan Catanzaro* 路 ([ultralong.github](https://ultralong.github.io/))
- **Efficient Pretraining Length Scaling**, `arXiv, 2504.14992`, [arxiv](http://arxiv.org/abs/2504.14992v2), [pdf](http://arxiv.org/pdf/2504.14992v2.pdf), cication: [**-1**](None) 

	 *Bohong Wu, Shen Yan, Sijun Zhang, ..., Ya Wang, Xun Zhou*
- **Eagle 2.5: Boosting Long-Context Post-Training for Frontier 
  Vision-Language Models**, `arXiv, 2504.15271`, [arxiv](http://arxiv.org/abs/2504.15271v1), [pdf](http://arxiv.org/pdf/2504.15271v1.pdf), cication: [**-1**](None) 

	 *Guo Chen, Zhiqi Li, Shihao Wang, ..., Zhiding Yu, Guilin Liu*
- **Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression**, `arXiv, 2503.02812`, [arxiv](http://arxiv.org/abs/2503.02812v1), [pdf](http://arxiv.org/pdf/2503.02812v1.pdf), cication: [**-1**](None) 

	 *Nathan Godey, Alessio Devoto, Yu Zhao, ..., ric de la Clergerie, Beno卯t Sagot* 路 ([](https://x.com/nthngdy/status/1897301390470603245))
- **From Hours to Minutes: Lossless Acceleration of Ultra Long Sequence 
  Generation up to 100K Tokens**, `arXiv, 2502.18890`, [arxiv](http://arxiv.org/abs/2502.18890v1), [pdf](http://arxiv.org/pdf/2502.18890v1.pdf), cication: [**-1**](None) 

	 *Tong Wu, Junzhe Shen, Zixia Jia, ..., Yuxuan Wang, Zilong Zheng* 路 ([TokenSwift](https://github.com/bigai-nlco/TokenSwift) - bigai-nlco) ![Star](https://img.shields.io/github/stars/bigai-nlco/TokenSwift.svg?style=social&label=Star) 路 ([arxiv](https://arxiv.org/abs/2502.18890)) 路 ([huggingface](https://huggingface.co/TokenSwift))
- **LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in 
  Vision-Language Models**, `arXiv, 2502.14834`, [arxiv](http://arxiv.org/abs/2502.14834v1), [pdf](http://arxiv.org/pdf/2502.14834v1.pdf), cication: [**-1**](None) 

	 *Shangqing Tu, Yucheng Wang, Daniel Zhang-Li, ..., Bin Xu, Juanzi Li*
- **MoBA: Mixture of Block Attention for Long-Context LLMs**, `arXiv, 2502.13189`, [arxiv](http://arxiv.org/abs/2502.13189v1), [pdf](http://arxiv.org/pdf/2502.13189v1.pdf), cication: [**-1**](None) 

	 *Enzhe Lu, Zhejun Jiang, Jingyuan Liu, ..., Mingxing Zhang, Jiezhong Qiu* 路 ([MoBA](https://github.com/MoonshotAI/MoBA) - MoonshotAI) ![Star](https://img.shields.io/github/stars/MoonshotAI/MoBA.svg?style=social&label=Star)
- **LongRoPE2: Near-Lossless LLM Context Window Scaling**, `arXiv, 2502.20082`, [arxiv](http://arxiv.org/abs/2502.20082v1), [pdf](http://arxiv.org/pdf/2502.20082v1.pdf), cication: [**-1**](None) 

	 *Ning Shang, Li Lyna Zhang, Siyuan Wang, ..., Weizhu Chen, Mao Yang* 路 ([LongRoPE](https://github.com/microsoft/LongRoPE) - microsoft) ![Star](https://img.shields.io/github/stars/microsoft/LongRoPE.svg?style=social&label=Star) 路 ([](https://x.com/LynaZhang/status/1896111430837158042))
- **Thus Spake Long-Context Large Language Model**, `arXiv, 2502.17129`, [arxiv](http://arxiv.org/abs/2502.17129v1), [pdf](http://arxiv.org/pdf/2502.17129v1.pdf), cication: [**-1**](None) 

	 *Xiaoran Liu, Ruixiao Li, Mianqiu Huang, ..., Xuanjing Huang, Xipeng Qiu* 路 ([Thus-Spake-Long-Context-LLM](https://github.com/OpenMOSS/Thus-Spake-Long-Context-LLM) - OpenMOSS) ![Star](https://img.shields.io/github/stars/OpenMOSS/Thus-Spake-Long-Context-LLM.svg?style=social&label=Star) 路 ([bilibili](https://www.bilibili.com/video/BV11h9AYoEY))
-  **InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on 
  a Single GPU**, `arXiv, 2502.08910`, [arxiv](http://arxiv.org/abs/2502.08910v1), [pdf](http://arxiv.org/pdf/2502.08910v1.pdf), cication: [**-1**](None) 

	 *Heejun Lee, Geon Park, Jaduk Suh, ..., Sung Ju Hwang* 路 ([huggingface](https://huggingface.co/papers/2502.08910)) 路 ([hip-attention](https://github.com/DeepAuto-AI/hip-attention/) - DeepAuto-AI) ![Star](https://img.shields.io/github/stars/DeepAuto-AI/hip-attention.svg?style=social&label=Star) 路 ([sglang](https://github.com/DeepAuto-AI/sglang/) - DeepAuto-AI) ![Star](https://img.shields.io/github/stars/DeepAuto-AI/sglang.svg?style=social&label=Star)
-  **LM2: Large Memory Models**, `arXiv, 2502.06049`, [arxiv](http://arxiv.org/abs/2502.06049v1), [pdf](http://arxiv.org/pdf/2502.06049v1.pdf), cication: [**-1**](None) 

	 *Jikun Kang, Wenqi Wu, Filippos Christianos, ..., Marvin Purtorab, Andy Toulis*
- [Qwen2.5-1M: Deploy Your Own Qwen with Context Length up to 1M Tokens](https://qwenlm.github.io/blog/qwen2.5-1m/) 
- **Titans: Learning to Memorize at Test Time**, `arXiv, 2501.00663`, [arxiv](http://arxiv.org/abs/2501.00663v1), [pdf](http://arxiv.org/pdf/2501.00663v1.pdf), cication: [**-1**](None) 

	 *Ali Behrouz, Peilin Zhong, Vahab Mirrokni*
- [Stick-breaking Attention](https://openreview.net/forum?id=r8J3DSD5kF) 

	 路 ([](https://x.com/_arohan_/status/1877795996815728987))
- **Long Context vs. RAG for LLMs: An Evaluation and Revisits**, `arXiv, 2501.01880`, [arxiv](http://arxiv.org/abs/2501.01880v1), [pdf](http://arxiv.org/pdf/2501.01880v1.pdf), cication: [**-1**](None) 

	 *Xinze Li, Yixin Cao, Yubo Ma, ..., Aixin Sun*
- **SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation**, `arXiv, 2412.13649`, [arxiv](http://arxiv.org/abs/2412.13649v1), [pdf](http://arxiv.org/pdf/2412.13649v1.pdf), cication: [**-1**](None) 

	 *Jialong Wu, Zhenglin Wang, Linhai Zhang, ..., Yulan He, Deyu Zhou* 路 ([SCOPE.](https://github.com/Linking-ai/SCOPE.) - Linking-ai) ![Star](https://img.shields.io/github/stars/Linking-ai/SCOPE..svg?style=social&label=Star)
- **Revisiting In-Context Learning with Long Context Language Models**, `arXiv, 2412.16926`, [arxiv](http://arxiv.org/abs/2412.16926v1), [pdf](http://arxiv.org/pdf/2412.16926v1.pdf), cication: [**-1**](None) 

	 *Jinheon Baek, Sun Jae Lee, Prakhar Gupta, ..., Siddharth Dalmia, Prateek Kolhar*
- **Fourier Position Embedding: Enhancing Attention's Periodic Extension for 
  Length Generalization**, `arXiv, 2412.17739`, [arxiv](http://arxiv.org/abs/2412.17739v1), [pdf](http://arxiv.org/pdf/2412.17739v1.pdf), cication: [**-1**](None) 

	 *Ermo Hua, Che Jiang, Xingtai Lv, ..., Xue Kai Zhu, Bowen Zhou*
- **SCBench: A KV Cache-Centric Analysis of Long-Context Methods**, `arXiv, 2412.10319`, [arxiv](http://arxiv.org/abs/2412.10319v1), [pdf](http://arxiv.org/pdf/2412.10319v1.pdf), cication: [**-1**](None) 

	 *Yucheng Li, Huiqiang Jiang, Qianhui Wu, ..., Yuqing Yang, Lili Qiu* 路 ([aka](https://aka.ms/SCBench))
- **Star Attention: Efficient LLM Inference over Long Sequences**, `arXiv, 2411.17116`, [arxiv](http://arxiv.org/abs/2411.17116v1), [pdf](http://arxiv.org/pdf/2411.17116v1.pdf), cication: [**-1**](None) 

	 *Shantanu Acharya, Fei Jia, Boris Ginsburg* 路 ([Star-Attention](https://github.com/NVIDIA/Star-Attention?tab=readme-ov-file) - NVIDIA) ![Star](https://img.shields.io/github/stars/NVIDIA/Star-Attention.svg?style=social&label=Star)
- **When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context 
  Training**, `arXiv, 2411.13476`, [arxiv](http://arxiv.org/abs/2411.13476v1), [pdf](http://arxiv.org/pdf/2411.13476v1.pdf), cication: [**-1**](None) 

	 *Haonan Wang, Qian Liu, Chao Du, ..., Kenji Kawaguchi, Tianyu Pang* 路 ([AnchorContext](https://github.com/haonan3/AnchorContext) - haonan3) ![Star](https://img.shields.io/github/stars/haonan3/AnchorContext.svg?style=social&label=Star)
- **Long Term Memory: The Foundation of AI Self-Evolution**, `arXiv, 2410.15665`, [arxiv](http://arxiv.org/abs/2410.15665v2), [pdf](http://arxiv.org/pdf/2410.15665v2.pdf), cication: [**-1**](None) 

	 *Xun Jiang, Feng Li, Han Zhao, ..., Mengdi Wang, Tianqiao Chen* 路 ([](https://x.com/TankaChat/status/1857272126358880267))
- **Large Language Models Can Self-Improve in Long-context Reasoning**, `arXiv, 2411.08147`, [arxiv](http://arxiv.org/abs/2411.08147v1), [pdf](http://arxiv.org/pdf/2411.08147v1.pdf), cication: [**-1**](None) 

	 *Siheng Li, Cheng Yang, Zesen Cheng, ..., Yujiu Yang, Wai Lam*
- **KV-Compress: Paged KV-Cache Compression with Variable Compression Rates 
  per Attention Head**, `arXiv, 2410.00161`, [arxiv](http://arxiv.org/abs/2410.00161v2), [pdf](http://arxiv.org/pdf/2410.00161v2.pdf), cication: [**-1**](None) 

	 *Isaac Rehg*

	 路 ([vllm-kvcompress](https://github.com/IsaacRe/vllm-kvcompress/tree/main?tab=readme-ov-file) - IsaacRe) ![Star](https://img.shields.io/github/stars/IsaacRe/vllm-kvcompress.svg?style=social&label=Star)
- **A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache 
  Compression**, `arXiv, 2406.11430`, [arxiv](http://arxiv.org/abs/2406.11430v3), [pdf](http://arxiv.org/pdf/2406.11430v3.pdf), cication: [**5**](https://scholar.google.com/scholar?cites=5168052951707843815&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Alessio Devoto, Yu Zhao, Simone Scardapane, ..., Pasquale Minervini*
- **Language Models can Self-Lengthen to Generate Long Texts**, `arXiv, 2410.23933`, [arxiv](http://arxiv.org/abs/2410.23933v1), [pdf](http://arxiv.org/pdf/2410.23933v1.pdf), cication: [**-1**](None) 

	 *Shanghaoran Quan, Tianyi Tang, Bowen Yu, ..., Jingren Zhou, Junyang Lin* 路 ([Self-Lengthen](https://github.com/QwenLM/Self-Lengthen) - QwenLM) ![Star](https://img.shields.io/github/stars/QwenLM/Self-Lengthen.svg?style=social&label=Star)
- **ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM 
  Inference**, `arXiv, 2410.21465`, [arxiv](http://arxiv.org/abs/2410.21465v1), [pdf](http://arxiv.org/pdf/2410.21465v1.pdf), cication: [**-1**](None)

	 *Hanshi Sun, Li-Wen Chang, Wenlei Bao, ..., Yuejie Chi, Beidi Chen* 路 ([ShadowKV](https://github.com/bytedance/ShadowKV) - bytedance) ![Star](https://img.shields.io/github/stars/bytedance/ShadowKV.svg?style=social&label=Star)
- **LongReward: Improving Long-context Large Language Models with AI 
  Feedback**, `arXiv, 2410.21252`, [arxiv](http://arxiv.org/abs/2410.21252v1), [pdf](http://arxiv.org/pdf/2410.21252v1.pdf), cication: [**-1**](None)

	 *Jiajie Zhang, Zhongni Hou, Xin Lv, ..., Ling Feng, Juanzi Li* 路 ([LongReward](https://github.com/THUDM/LongReward) - THUDM) ![Star](https://img.shields.io/github/stars/THUDM/LongReward.svg?style=social&label=Star) 路 ([huggingface](https://huggingface.co/datasets/THUDM/LongReward-10k))
- **In Defense of RAG in the Era of Long-Context Language Models**, `arXiv, 2409.01666`, [arxiv](http://arxiv.org/abs/2409.01666v1), [pdf](http://arxiv.org/pdf/2409.01666v1.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=3261789221345650637&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Tan Yu, Anbang Xu, Rama Akkiraju* 路 ([zyphra](https://www.zyphra.com/post/reaching-1b-context-length-with-rag))
- **LOGO -- Long cOntext aliGnment via efficient preference Optimization**, `arXiv, 2410.18533`, [arxiv](http://arxiv.org/abs/2410.18533v1), [pdf](http://arxiv.org/pdf/2410.18533v1.pdf), cication: [**-1**](None) 

	 *Zecheng Tang, Zechen Sun, Juntao Li, ..., Qiaoming Zhu, Min Zhang*
- **How to Train Long-Context Language Models (Effectively)**, `arXiv, 2410.02660`, [arxiv](http://arxiv.org/abs/2410.02660v1), [pdf](http://arxiv.org/pdf/2410.02660v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=16129934205797752579&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII) 

	 *Tianyu Gao, Alexander Wettig, Howard Yen, ..., Danqi Chen*

	 路 ([prolong](https://github.com/princeton-nlp/prolong?tab=readme-ov-file) - princeton-nlp) ![Star](https://img.shields.io/github/stars/princeton-nlp/prolong.svg?style=social&label=Star)
- **Why Does the Effective Context Length of LLMs Fall Short?**, `arXiv, 2410.18745`, [arxiv](http://arxiv.org/abs/2410.18745v1), [pdf](http://arxiv.org/pdf/2410.18745v1.pdf), cication: [**-1**](None) 

	 *Chenxin An, Jun Zhang, Ming Zhong, ..., Jingjing Xu, Lingpeng Kong*

	 路 ([STRING](https://github.com/HKUNLP/STRING) - HKUNLP) ![Star](https://img.shields.io/github/stars/HKUNLP/STRING.svg?style=social&label=Star)
- **LLM$\times$MapReduce: Simplified Long-Sequence Processing using Large 
  Language Models**, `arXiv, 2410.09342`, [arxiv](http://arxiv.org/abs/2410.09342v1), [pdf](http://arxiv.org/pdf/2410.09342v1.pdf), cication: [**-1**](None)

	 *Zihan Zhou, Chong Li, Xinyi Chen, ..., Zhiyuan Liu, Maosong Sun*

## Evaluation

-  **MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents**, `arXiv, 2501.08828`, [arxiv](http://arxiv.org/abs/2501.08828v1), [pdf](http://arxiv.org/pdf/2501.08828v1.pdf), cication: [**-1**](None) 

	 *Kuicai Dong, Yujing Chang, Xin Deik Goh, ..., Ruiming Tang, Yong Liu*

## Projects

- [**EM-LLM-model**](https://github.com/em-llm/EM-LLM-model) - em-llm ![Star](https://img.shields.io/github/stars/em-llm/EM-LLM-model.svg?style=social&label=Star) 

	 *Human-inspired Episodic Memory for Infinite Context LLMs*
- [**360-LLaMA-Factory**](https://github.com/Qihoo360/360-LLaMA-Factory) - Qihoo360 ![Star](https://img.shields.io/github/stars/Qihoo360/360-LLaMA-Factory.svg?style=social&label=Star) 
- [**LLMTest_NeedleInAHaystack**](https://github.com/gkamradt/LLMTest_NeedleInAHaystack) - gkamradt ![Star](https://img.shields.io/github/stars/gkamradt/LLMTest_NeedleInAHaystack.svg?style=social&label=Star) 
- [**KVCache-Factory**](https://github.com/Zefan-Cai/KVCache-Factory) - Zefan-Cai ![Star](https://img.shields.io/github/stars/Zefan-Cai/KVCache-Factory.svg?style=social&label=Star) 
- [**Awesome-LLM-Long-Context-Modeling**](https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling) - Xnhyacinth ![Star](https://img.shields.io/github/stars/Xnhyacinth/Awesome-LLM-Long-Context-Modeling.svg?style=social&label=Star) 

## Misc
## Misc
- [Extending the Context Length to 1M Tokens!](http://qwenlm.github.io/blog/qwen2.5-turbo/) 