# Open LLM

- [Open LLM](#open-llm) 
  - [Survey](#survey)
  - [Open LLM](#open-llm-1)
  - [English Models](#english-models)
  - [Chinese Models](#chinese-models)
  - [Small Language Models](#small-language-models)
  - [Multilingual Models](#multilingual-models)
  - [Toolkits](#toolkits)
  - [Misc](#misc)


## Survey


## Open LLM


## English Models

- [AMD-OLMo are a series of 1 billion parameter language models trained by AMD on AMD Instinct‚Ñ¢ MI250 GPUs based on OLMo.](https://huggingface.co/collections/amd/amd-olmo-6723e7d04a49116d8ec95070)  ü§ó
- [Steiner is a series of reasoning models trained on synthetic data using reinforcement learning.](https://huggingface.co/peakji/steiner-32b-preview)  ü§ó
- [Granite 3.0 models](https://huggingface.co/collections/ibm-granite/granite-30-models-66fdb59bbb54785c3512114f)  ü§ó

## Chinese Models


## Small Language Models

- [State-of-the-art compact LLMs for on-device applications: 1.7B, 360M, 135M    Upvote 107   +97](https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9)  ü§ó

	 ¬∑ ([x](https://x.com/loubnabenallal1/status/1852055582494294414?s=46&t=MGz8l5Z36lvN2cHgl1IVqA))
- [SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters.](https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct)  ü§ó
- [MobileLLM is an auto-regressive language model leveraging an optimized transformer architecture](https://huggingface.co/facebook/MobileLLM-125M)  ü§ó

	 ¬∑ ([arxiv](https://arxiv.org/abs/2402.14905))

## Multilingual Models

- **Bielik 7B v0.1: A Polish Language Model -- Development, Insights, and 
  Evaluation**, `arXiv, 2410.18565`, [arxiv](http://arxiv.org/abs/2410.18565v1), [pdf](http://arxiv.org/pdf/2410.18565v1.pdf), cication: [**-1**](None)

	 *Krzysztof Ociepa, ≈Åukasz Flis, Krzysztof Wr√≥bel, ..., Adrian Gwo≈∫dziej, Remigiusz Kinas* ¬∑ ([bielik](https://bielik.ai/)) ¬∑ ([huggingface](https://huggingface.co/speakleash/Bielik-11B-v2.3-Instruct))
- :clapper: [Multilinguality and LLMs Special Session](https://www.youtube.com/watch?v=aNPa00_-DbA) 
- **Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages**, `arXiv, 2410.16153`, [arxiv](http://arxiv.org/abs/2410.16153v1), [pdf](http://arxiv.org/pdf/2410.16153v1.pdf), cication: [**-1**](None) 

	 *Xiang Yue, Yueqi Song, Akari Asai, ..., Sathyanarayanan Ramamoorthy, Graham Neubig* ¬∑ ([Pangea](https://github.com/neulab/Pangea) - neulab) ![Star](https://img.shields.io/github/stars/neulab/Pangea.svg?style=social&label=Star) ¬∑ ([neulab.github](https://neulab.github.io/Pangea/)) ¬∑ ([x](https://x.com/xiangyue96/status/1848753709787795679))

## Toolkits


## Misc