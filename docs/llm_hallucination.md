# LLM Hallucination

- [LLM Hallucination](#llm-hallucination)
  - [Survey](#survey)
  - [Hallucination](#hallucination)
  - [Evaluation](#evaluation)
  - [Multi Modal](#multi-modal)
  - [Projects](#projects)
  - [Misc](#misc)


## Survey


## Hallucination


## Evaluation


## Multi Modal

- **MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation**, `arXiv, 2410.11779`, [arxiv](http://arxiv.org/abs/2410.11779v1), [pdf](http://arxiv.org/pdf/2410.11779v1.pdf), cication: [**-1**](None)

	 *Chenxi Wang, Xiang Chen, Ningyu Zhang, ..., Shumin Deng, Huajun Chen*
- **The Curse of Multi-Modalities: Evaluating Hallucinations of Large
  Multimodal Models across Language, Visual, and Audio**, `arXiv, 2410.12787`, [arxiv](http://arxiv.org/abs/2410.12787v1), [pdf](http://arxiv.org/pdf/2410.12787v1.pdf), cication: [**-1**](None)

	 *Sicong Leng, Yun Xing, Zesen Cheng, ..., Chunyan Miao, Lidong Bing*

## Projects

- [**hallucination-leaderboard**](https://github.com/vectara/hallucination-leaderboard) - vectara ![Star](https://img.shields.io/github/stars/vectara/hallucination-leaderboard.svg?style=social&label=Star)

## Misc

