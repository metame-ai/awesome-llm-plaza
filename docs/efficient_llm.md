# Efficient LLM

- [Efficient LLM](#efficient-llm)
  - [Survey](#survey)
  - [Efficient LLM](#efficient-llm-1)
  - [Finetune](#finetune)
  - [Quantization](#quantization)
  - [Distillation](#distillation)
  - [Pruning](#pruning)
  - [Inference](#inference)
  - [Mobile](#mobile)
  - [Transformer](#transformer)
  - [Hardware](#hardware)
  - [Tutorials](#tutorials)
  - [Projects](#projects)
  - [Products](#products)
  - [Misc](#misc)


## Survey


## Efficient LLM


## Finetune


## Quantization


## Distillation


## Pruning

- **What Matters in Transformers? Not All Attention is Needed**, `arXiv, 2406.15786`, [arxiv](http://arxiv.org/abs/2406.15786v6), [pdf](http://arxiv.org/pdf/2406.15786v6.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=18204847320375312044&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Shwai He, Guoheng Sun, Zheyu Shen, ..., Ang Li*

## Inference

- [Battle of Inference Engines: Llama.cpp vs MLC LLM vs vLLM](https://buttondown.com/ainews/archive/ainews-not-much-happened-this-weekend-2670/)

	 · ([reddit](https://www.reddit.com/gallery/1gdccyr))
- [Universal Assisted Generation: Faster Decoding with Any Assistant Model](https://huggingface.co/blog/universal_assisted_generation)
- [Models continually pretrained using LayerSkip](https://huggingface.co/collections/facebook/layerskip-666b25c50c8ae90e1965727a)

	 · ([arxiv](https://arxiv.org/abs/2404.16710))

## Mobile


## Transformer

- [Differential Transformer 论文原理逐段讲解](https://www.bilibili.com/video/BV1Jq1PYPEYG/)
- **SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs**, `arXiv, 2410.13276`, [arxiv](http://arxiv.org/abs/2410.13276v2), [pdf](http://arxiv.org/pdf/2410.13276v2.pdf), cication: [**-1**](None)

	 *Yizhao Gao, Zhichen Zeng, Dayou Du, ..., Fan Yang, Mao Yang*
- **MoH: Multi-Head Attention as Mixture-of-Head Attention**, `arXiv, 2410.11842`, [arxiv](http://arxiv.org/abs/2410.11842v1), [pdf](http://arxiv.org/pdf/2410.11842v1.pdf), cication: [**-1**](None)

	 *Peng Jin, Bo Zhu, Li Yuan, ..., Shuicheng Yan* · ([arxiv](https://arxiv.org/pdf/2410.11842)) · ([MoH](https://github.com/SkyworkAI/MoH) - SkyworkAI) ![Star](https://img.shields.io/github/stars/SkyworkAI/MoH.svg?style=social&label=Star) · ([huggingface](https://huggingface.co/collections/Chat-UniVi/moh-66f4277375c1c1b2ad61a2c1))

## Hardware

- [database of Machine Learning Hardware](https://x.com/EpochAIResearch/status/1849135255833158124)

## Tutorials

- [Lecture 32: Unsloth](https://www.youtube.com/watch?v=hfb_AIhDYnA)

## Projects


## Products


## Misc

- [How FlashAttention Accelerates the Generative AI Revolution](https://www.youtube.com/watch?v=gBMO1JZav44)
- [k-mktr / gpu-poor-llm-arena](https://huggingface.co/spaces/k-mktr/gpu-poor-llm-arena/tree/main)