# LLM RLHF

- [LLM RLHF](#llm-rlhf)
  - [Survey](#survey)
  - [RLHF](#rlhf)
  - [Reward Models](#reward-models)
  - [Projects](#projects)
  - [Misc](#misc)


## Survey


## RLHF

- [Thinking LLMs: General Instruction Following With Thought Generation](https://x.com/rasbt/status/1850177459930497118)
- [Paper page - MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large  Vision-Language Models](https://huggingface.co/papers/2410.17637)

## Reward Models

- [Paper page - Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs](https://huggingface.co/papers/2410.18451)

	 · ([huggingface](https://huggingface.co/Skywork/Skywork-Reward-Llama-3.1-8B-v0.2)) · ([huggingface](https://huggingface.co/Skywork/Skywork-Reward-Gemma-2-27B-v0.2)) · ([huggingface](https://huggingface.co/datasets/Skywork/Skywork-Reward-Preference-80K-v0.2))
- [benchmark: Preference Proxy Evaluations (PPE)](https://x.com/lmarena_ai/status/1848778976585781369)

	 · ([blog.lmarena](https://blog.lmarena.ai/blog/2024/preference-proxy-evaluations/)) · ([arxiv](https://arxiv.org/abs/2410.14872)) · ([PPE](https://github.com/lmarena/PPE) - lmarena) ![Star](https://img.shields.io/github/stars/lmarena/PPE.svg?style=social&label=Star)
- **RM-Bench: Benchmarking Reward Models of Language Models with Subtlety
  and Style**, `arXiv, 2410.16184`, [arxiv](http://arxiv.org/abs/2410.16184v1), [pdf](http://arxiv.org/pdf/2410.16184v1.pdf), cication: [**-1**](None)

	 *Yantao Liu, Zijun Yao, Rui Min, ..., Lei Hou, Juanzi Li* · ([RM-Bench](https://github.com/THU-KEG/RM-Bench) - THU-KEG) ![Star](https://img.shields.io/github/stars/THU-KEG/RM-Bench.svg?style=social&label=Star)

## Projects


## Misc
