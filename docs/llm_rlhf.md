# LLM RLHF

- [LLM RLHF](#llm-rlhf)
  - [Survey](#survey)
  - [RLHF](#rlhf)
  - [Reward Models](#reward-models)
  - [Projects](#projects)
  - [Misc](#misc)


## Survey


## RLHF


## Reward Models

- [benchmark: Preference Proxy Evaluations (PPE)](https://x.com/lmarena_ai/status/1848778976585781369)
   - [blog.lmarena.ai](https://blog.lmarena.ai/blog/2024/preference-proxy-evaluations/)
   - [arxiv.org](https://arxiv.org/abs/2410.14872)
   - [github.com](https://github.com/lmarena/PPE)
- [Paper page - RM-Bench: Benchmarking Reward Models of Language Models with Subtlety  and Style](https://huggingface.co/papers/2410.16184)
   - [github.com](https://github.com/THU-KEG/RM-Bench)

## Projects


## Misc


